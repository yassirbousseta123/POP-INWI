import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from data_loader import DataCleaner
import warnings
warnings.filterwarnings('ignore')

# Import Unified Period Selector
from src.ui.period_selector import period_selector

# Import Incident Lens UI
try:
    from src.ui.incident_lens_ui import render_incident_lens_interface, render_incident_lens_summary
except ImportError as e:
    st.error(f"Erreur d'import Incident Lens: {e}")
    render_incident_lens_interface = None
    render_incident_lens_summary = None

# Configuration de la page
st.set_page_config(
    page_title="BGU-ONE Centre de Donn√©es - Tableau de Bord",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style CSS personnalis√©
st.markdown("""
<style>
    .main {
        padding: 0rem 1rem;
    }
    .stTitle {
        color: #1E3A8A;
        font-size: 2.5rem !important;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-container {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .stPlotlyChart {
        background-color: white;
        border-radius: 0.5rem;
        padding: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# Titre principal avec logo INWI
col_title, col_spacer, col_logo = st.columns([5, 0.5, 1])
with col_title:
    st.markdown("<h1 style='margin-top: 0; padding-top: 20px;'>üè¢ BGU-ONE Centre de Donn√©es - Tableau de Bord de Surveillance</h1>", unsafe_allow_html=True)
with col_spacer:
    st.empty()
with col_logo:
    st.markdown("<div style='text-align: right; padding-top: 10px; padding-right: 20px;'>", unsafe_allow_html=True)
    st.image("logo_inwi.png", width=200)
    st.markdown("</div>", unsafe_allow_html=True)
st.markdown("---")

# Initialisation du cache
@st.cache_data
def load_data():
    """Charge et nettoie toutes les donn√©es"""
    cleaner = DataCleaner()
    cleaned_data = cleaner.load_all_data()
    merged_data = cleaner.merge_all_data(cleaned_data)
    return cleaned_data, merged_data

# Initialize session state for period selector before anything else
if 'unified_period' not in st.session_state:
    end_date_default = datetime.now()
    start_date_default = end_date_default - timedelta(days=7)
    st.session_state.unified_period = {
        'start_date': start_date_default,
        'end_date': end_date_default,
        'selection_type': 'Derni√®re semaine',
        'custom_range': None
    }

# Chargement des donn√©es
with st.spinner("Chargement des donn√©es..."):
    cleaned_data, merged_data = load_data()

# Unified Period Selector in Sidebar
start_date, end_date = period_selector.render_mini_selector()

# Filter all data based on unified period
filtered_merged_data = period_selector.filter_dataframe(merged_data) if not merged_data.empty else merged_data

# Navigation horizontale
st.markdown("## üéØ Navigation")

# Cr√©er les onglets pour la navigation
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs([
    "üìä Vue d'ensemble",
    "üìà Analyse temporelle",
    "üî¨ Analyses EDA",
    "‚ùÑÔ∏è Analyse CLIM",
    "üö™ Analyse Porte",
    "üîç Incident Lens",
    "üîó Corr√©lations",
    "üìã Rapports",
    "üí∞ Simulation Co√ªts"
])


# 1. VUE D'ENSEMBLE
with tab1:
    st.header("üìä Vue d'ensemble du syst√®me")
    
    if not filtered_merged_data.empty and 'Timestamp' in filtered_merged_data.columns:
        # Display current unified period
        st.info(f"üìÖ P√©riode s√©lectionn√©e: {start_date.strftime('%Y-%m-%d %H:%M')} - {end_date.strftime('%Y-%m-%d %H:%M')}")
        
        # Use the already filtered data from unified selector
        filtered_data = filtered_merged_data
        
        if not filtered_data.empty:
            # M√©triques importantes
            st.subheader("üìä M√©triques cl√©s pour la p√©riode s√©lectionn√©e")
            
            # Fonction pour calculer les statistiques
            def calculate_stats(data, column):
                if column in data.columns:
                    # Filtrer les valeurs non-NaN
                    valid_data = data[column].dropna()
                    if len(valid_data) > 0:
                        return {
                            'min': valid_data.min(),
                            'max': valid_data.max(),
                            'mean': valid_data.mean(),
                            'median': valid_data.median()
                        }
                return {'min': 0, 'max': 0, 'mean': 0, 'median': 0}
            
            # Temp√©rature Ambiante
            st.markdown("### üå°Ô∏è Temp√©rature Ambiante")
            temp_amb_stats = calculate_stats(filtered_data, 'Temp_Ambiante')
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Min", f"{temp_amb_stats['min']:.1f}¬∞C")
            with col2:
                st.metric("Max", f"{temp_amb_stats['max']:.1f}¬∞C")
            with col3:
                st.metric("Moyenne", f"{temp_amb_stats['mean']:.1f}¬∞C")
            with col4:
                st.metric("M√©diane", f"{temp_amb_stats['median']:.1f}¬∞C")
            
            # Temp√©rature Ext√©rieure
            st.markdown("### üå§Ô∏è Temp√©rature Ext√©rieure")
            temp_ext_stats = calculate_stats(filtered_data, 'Temp_Exterieure')
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Min", f"{temp_ext_stats['min']:.1f}¬∞C")
            with col2:
                st.metric("Max", f"{temp_ext_stats['max']:.1f}¬∞C")
            with col3:
                st.metric("Moyenne", f"{temp_ext_stats['mean']:.1f}¬∞C")
            with col4:
                st.metric("M√©diane", f"{temp_ext_stats['median']:.1f}¬∞C")
            
            # Puissance IT
            st.markdown("### üíª Puissance IT")
            puiss_it_stats = calculate_stats(filtered_data, 'Puissance_IT')
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Min", f"{puiss_it_stats['min']:.1f} kW")
            with col2:
                st.metric("Max", f"{puiss_it_stats['max']:.1f} kW")
            with col3:
                st.metric("Moyenne", f"{puiss_it_stats['mean']:.1f} kW")
            with col4:
                st.metric("M√©diane", f"{puiss_it_stats['median']:.1f} kW")
            
            # Graphique temporel unifi√©
            st.subheader("üìà √âvolution temporelle")
            
            # S√©lection des donn√©es √† afficher
            available_metrics = {
                'Temp_Ambiante': 'üå°Ô∏è Temp√©rature Ambiante (¬∞C)',
                'Temp_Exterieure': 'üå§Ô∏è Temp√©rature Ext√©rieure (¬∞C)',
                'Puissance_IT': 'üíª Puissance IT (kW)',
                'Puissance_Generale': '‚ö° Puissance G√©n√©rale (kW)',
                'Puissance_CLIM': '‚ùÑÔ∏è Puissance CLIM (kW)',
                'CLIM_A_Status': '‚ùÑÔ∏è √âtat CLIM A',
                'CLIM_B_Status': '‚ùÑÔ∏è √âtat CLIM B',
                'CLIM_C_Status': '‚ùÑÔ∏è √âtat CLIM C',
                'CLIM_D_Status': '‚ùÑÔ∏è √âtat CLIM D',
                'Porte_Status': 'üö™ √âtat Porte'
            }
            
            # Filtrer les m√©triques disponibles
            available_cols = [col for col in available_metrics.keys() if col in filtered_data.columns]
            
            # Afficher des informations sur la disponibilit√© des donn√©es
            with st.expander("‚ÑπÔ∏è Informations sur les donn√©es disponibles"):
                for col in available_cols:
                    valid_count = filtered_data[col].notna().sum()
                    total_count = len(filtered_data)
                    percentage = (valid_count / total_count * 100) if total_count > 0 else 0
                    st.text(f"{available_metrics[col]}: {valid_count}/{total_count} points ({percentage:.1f}%)")
            
            # Boutons de s√©lection rapide
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                if st.button("üå°Ô∏è Toutes Temp√©ratures"):
                    temp_metrics = [col for col in available_cols if 'Temp' in col]
                    st.session_state['selected_metrics'] = temp_metrics
            with col2:
                if st.button("‚ö° Toutes Puissances"):
                    power_metrics = [col for col in available_cols if 'Puissance' in col]
                    st.session_state['selected_metrics'] = power_metrics
            with col3:
                if st.button("‚ùÑÔ∏è Tous CLIMs"):
                    clim_metrics = [col for col in available_cols if 'CLIM' in col and 'Status' in col]
                    st.session_state['selected_metrics'] = clim_metrics
            with col4:
                if st.button("üìä Tout S√©lectionner"):
                    st.session_state['selected_metrics'] = available_cols
            
            selected_metrics = st.multiselect(
                "S√©lectionner les donn√©es √† afficher dans le graphique:",
                available_cols,
                default=st.session_state.get('selected_metrics', ['Temp_Ambiante', 'Temp_Exterieure', 'Puissance_IT'] if all(col in available_cols for col in ['Temp_Ambiante', 'Temp_Exterieure', 'Puissance_IT']) else available_cols[:3]),
                format_func=lambda x: available_metrics[x]
            )
            
            if selected_metrics:
                # Cr√©er un graphique unifi√© avec axes secondaires si n√©cessaire
                fig = go.Figure()
                
                # Nouvelles couleurs optimis√©es pour la superposition avec transparence
                # Couleurs s√©mantiques et contrast√©es pour une meilleure visibilit√© en superposition
                color_scheme = {
                    # Temp√©ratures - tons bleus/cyan
                    'Temp_Ambiante': {'color': '#2E86AB', 'fill': 'rgba(46, 134, 171, 0.4)'},
                    'Temp_Exterieure': {'color': '#A23B72', 'fill': 'rgba(162, 59, 114, 0.3)'},
                    
                    # Puissances - tons orange/rouge
                    'Puissance_IT': {'color': '#F18F01', 'fill': 'rgba(241, 143, 1, 0.5)'},
                    'Puissance_Generale': {'color': '#C73E1D', 'fill': 'rgba(199, 62, 29, 0.4)'},
                    'Puissance_CLIM': {'color': '#FF6B6B', 'fill': 'rgba(255, 107, 107, 0.3)'},
                    
                    # √âtats CLIM - tons verts avec transparence √©lev√©e
                    'CLIM_A_Status': {'color': '#4ECDC4', 'fill': 'rgba(78, 205, 196, 0.6)'},
                    'CLIM_B_Status': {'color': '#45B7D1', 'fill': 'rgba(69, 183, 209, 0.6)'},
                    'CLIM_C_Status': {'color': '#96CEB4', 'fill': 'rgba(150, 206, 180, 0.6)'},
                    'CLIM_D_Status': {'color': '#FECA57', 'fill': 'rgba(254, 202, 87, 0.6)'},
                    
                    # Porte - ton violet
                    'Porte_Status': {'color': '#6C5CE7', 'fill': 'rgba(108, 92, 231, 0.7)'}
                }
                
                # Couleurs de fallback pour m√©triques non d√©finies
                fallback_colors = [
                    {'color': '#FF9F43', 'fill': 'rgba(255, 159, 67, 0.4)'},
                    {'color': '#10AC84', 'fill': 'rgba(16, 172, 132, 0.4)'},
                    {'color': '#EE5A24', 'fill': 'rgba(238, 90, 36, 0.4)'},
                    {'color': '#0984e3', 'fill': 'rgba(9, 132, 227, 0.4)'},
                    {'color': '#a29bfe', 'fill': 'rgba(162, 155, 254, 0.4)'},
                    {'color': '#fd79a8', 'fill': 'rgba(253, 121, 168, 0.4)'},
                    {'color': '#fdcb6e', 'fill': 'rgba(253, 203, 110, 0.4)'},
                    {'color': '#6c5ce7', 'fill': 'rgba(108, 92, 231, 0.4)'}
                ]
                
                # D√©terminer si on a besoin d'axes secondaires
                has_temp = any('Temp' in m for m in selected_metrics)
                has_power = any('Puissance' in m for m in selected_metrics)
                has_status = any('Status' in m for m in selected_metrics)
                
                # S√©parer les donn√©es continues des donn√©es binaires
                continuous_metrics = [m for m in selected_metrics if 'Status' not in m]
                binary_metrics = [m for m in selected_metrics if 'Status' in m]
                
                # Option d'affichage pour les donn√©es binaires
                col1, col2 = st.columns([3, 1])
                with col2:
                    binary_display = st.selectbox(
                        "Affichage binaires:",
                        ["Superpos√©es transparentes", "S√©par√©es classiques"],
                        help="Superpos√©es: donn√©es binaires empil√©es avec transparence par-dessus les continues. S√©par√©es: affichage classique."
                    )
                
                # 1. COUCHE DE FOND : Tracer d'abord toutes les donn√©es continues normalement
                for idx, metric in enumerate(continuous_metrics):
                    # Obtenir les couleurs pour cette m√©trique
                    if metric in color_scheme:
                        colors_data = color_scheme[metric]
                    else:
                        colors_data = fallback_colors[idx % len(fallback_colors)]
                    
                    # D√©terminer l'axe Y appropri√©
                    if 'Temp' in metric:
                        yaxis = 'y'
                    elif 'Puissance' in metric:
                        yaxis = 'y2' if has_temp else 'y'
                    
                    # Pr√©parer les donn√©es
                    mask_valid = filtered_data[metric].notna()
                    x_data = filtered_data.loc[mask_valid, 'Timestamp']
                    y_data = filtered_data.loc[mask_valid, metric]
                    
                    if len(x_data) > 0:
                        # Tracer les donn√©es continues normalement (pas de transparence)
                        fig.add_trace(go.Scatter(
                            x=x_data,
                            y=y_data,
                            name=available_metrics[metric],
                            mode='lines',
                            line=dict(color=colors_data['color'], width=2.5),
                            yaxis=yaxis,
                            connectgaps=True,
                            hovertemplate='<b>%{fullData.name}</b><br>Valeur: %{y:.2f}<br>Temps: %{x}<extra></extra>'
                        ))
                
                # 2. COUCHE SUPERPOS√âE : Tracer les donn√©es binaires par-dessus
                if binary_metrics and binary_display == "Superpos√©es transparentes":
                    # Calculer la plage des donn√©es continues pour normaliser les binaires
                    if continuous_metrics:
                        # Trouver min/max global des donn√©es continues pour la normalisation
                        all_continuous_values = []
                        for metric in continuous_metrics:
                            mask_valid = filtered_data[metric].notna()
                            if mask_valid.any():
                                all_continuous_values.extend(filtered_data.loc[mask_valid, metric].values)
                        
                        if all_continuous_values:
                            y_min, y_max = min(all_continuous_values), max(all_continuous_values)
                            y_range = y_max - y_min if y_max != y_min else 1
                            band_height = y_range * 0.15  # Chaque bande binaire = 15% de la plage
                        else:
                            y_min, y_max, y_range, band_height = 0, 1, 1, 0.2
                    else:
                        y_min, y_max, y_range, band_height = 0, 1, 1, 0.2
                    
                    # Tracer chaque donn√©e binaire comme une bande transparente empil√©e
                    for idx, metric in enumerate(binary_metrics):
                        # Couleurs pour les binaires avec forte transparence
                        binary_colors = [
                            {'color': '#4ECDC4', 'fill': 'rgba(78, 205, 196, 0.4)'},
                            {'color': '#45B7D1', 'fill': 'rgba(69, 183, 209, 0.4)'},
                            {'color': '#96CEB4', 'fill': 'rgba(150, 206, 180, 0.4)'},
                            {'color': '#FECA57', 'fill': 'rgba(254, 202, 87, 0.4)'},
                            {'color': '#6C5CE7', 'fill': 'rgba(108, 92, 231, 0.4)'}
                        ]
                        colors_data = binary_colors[idx % len(binary_colors)]
                        
                        # Pr√©parer les donn√©es binaires
                        mask_valid = filtered_data[metric].notna()
                        x_data = filtered_data.loc[mask_valid, 'Timestamp']
                        binary_values = filtered_data.loc[mask_valid, metric]
                        
                        if len(x_data) > 0:
                            # Cr√©er des bandes empil√©es pour les binaires
                            # Base de la bande actuelle
                            band_bottom = y_max + (idx * band_height * 0.6)  # Espacement entre bandes
                            
                            # Convertir les 0/1 en zones remplies
                            y_bottom = [band_bottom] * len(x_data)
                            y_top = [band_bottom + (band_height * 0.5 * val) for val in binary_values]
                            
                            # Trace pour le bas de la bande (invisible)
                            fig.add_trace(go.Scatter(
                                x=x_data,
                                y=y_bottom,
                                name=f"{available_metrics[metric]} (base)",
                                mode='lines',
                                line=dict(color='rgba(0,0,0,0)', width=0),
                                showlegend=False,
                                yaxis='y' if (continuous_metrics and 'Temp' in continuous_metrics[0]) else 'y',
                                hoverinfo='skip'
                            ))
                            
                            # Trace pour le haut de la bande (visible avec remplissage)
                            fig.add_trace(go.Scatter(
                                x=x_data,
                                y=y_top,
                                name=available_metrics[metric],
                                mode='lines',
                                line=dict(color=colors_data['color'], width=1),
                                fill='tonexty',  # Remplir entre cette trace et la pr√©c√©dente
                                fillcolor=colors_data['fill'],
                                yaxis='y' if (continuous_metrics and 'Temp' in continuous_metrics[0]) else 'y',
                                connectgaps=False,
                                hovertemplate='<b>%{fullData.name}</b><br>Valeur: %{customdata}<br>Temps: %{x}<extra></extra>',
                                customdata=binary_values
                            ))
                
                elif binary_metrics and binary_display == "S√©par√©es classiques":
                    # Mode classique pour les binaires
                    for idx, metric in enumerate(binary_metrics):
                        if metric in color_scheme:
                            colors_data = color_scheme[metric]
                        else:
                            colors_data = fallback_colors[(len(continuous_metrics) + idx) % len(fallback_colors)]
                        
                        yaxis = 'y3' if (has_temp and has_power) else ('y2' if (has_temp or has_power) else 'y')
                        
                        mask_valid = filtered_data[metric].notna()
                        x_data = filtered_data.loc[mask_valid, 'Timestamp']
                        y_data = filtered_data.loc[mask_valid, metric]
                        
                        if len(x_data) > 0:
                            fig.add_trace(go.Scatter(
                                x=x_data,
                                y=y_data,
                                name=available_metrics[metric],
                                mode='lines',
                                line=dict(shape='hv', color=colors_data['color'], width=2),
                                yaxis=yaxis,
                                connectgaps=False
                            ))
                
                # V√©rifier s'il y a des traces ajout√©es
                if len(fig.data) == 0:
                    st.warning("Aucune donn√©e valide trouv√©e pour les m√©triques s√©lectionn√©es dans la p√©riode choisie.")
                else:
                    # Configuration am√©lior√©e du layout pour la superposition
                    layout_config = {
                        'title': dict(
                            text=f'üìà √âvolution temporelle - {binary_display}',
                            font=dict(size=18, color='#2C3E50')
                        ),
                        'xaxis': dict(
                            title='Temps',
                            showgrid=True,
                            gridcolor='rgba(128,128,128,0.2)',
                            zeroline=False
                        ),
                        'hovermode': 'x unified',
                        'height': 700,
                        'plot_bgcolor': 'rgba(0,0,0,0)',
                        'paper_bgcolor': 'rgba(0,0,0,0)',
                        'legend': dict(
                            orientation="v",
                            yanchor="top",
                            y=1,
                            xanchor="left",
                            x=1.02,
                            bgcolor="rgba(255,255,255,0.8)",
                            bordercolor="rgba(128,128,128,0.3)",
                            borderwidth=1
                        ),
                        'margin': dict(r=200)  # Plus d'espace pour la l√©gende
                    }
                
                    # Configuration des axes Y pour le nouveau syst√®me de couches
                    # L'axe Y principal est toujours pour les donn√©es continues
                    if has_temp:
                        layout_config['yaxis'] = dict(
                            title='Temp√©rature (¬∞C)',
                            side='left',
                            showgrid=True,
                            gridcolor='rgba(128,128,128,0.2)',
                            zeroline=True,
                            zerolinecolor='rgba(128,128,128,0.4)',
                            titlefont=dict(color='#2E86AB')
                        )
                    
                    # Axe Y secondaire pour les puissances
                    if has_power and has_temp:
                        layout_config['yaxis2'] = dict(
                            title='Puissance (kW)',
                            overlaying='y',
                            side='right',
                            showgrid=False,
                            zeroline=False,
                            titlefont=dict(color='#F18F01')
                        )
                    elif has_power:
                        layout_config['yaxis'] = dict(
                            title='Puissance (kW)',
                            side='left',
                            showgrid=True,
                            gridcolor='rgba(128,128,128,0.2)',
                            zeroline=True,
                            zerolinecolor='rgba(128,128,128,0.4)',
                            titlefont=dict(color='#F18F01')
                        )
                    
                    # Ajouter troisi√®me axe pour binaires s√©par√©es si n√©cessaire
                    if binary_display == "S√©par√©es classiques" and binary_metrics:
                        if has_status and (has_temp or has_power):
                            if has_temp and has_power:
                                layout_config['yaxis3'] = dict(
                                    title='√âtat (0=OFF, 1=ON)',
                                    overlaying='y',
                                    side='right',
                                    position=0.85,
                                    anchor='free',
                                    tickvals=[0, 1],
                                    ticktext=['OFF', 'ON']
                                )
                                layout_config['xaxis']['domain'] = [0, 0.85]
                            else:
                                layout_config['yaxis2'] = dict(
                                    title='√âtat (0=OFF, 1=ON)',
                                    overlaying='y',
                                    side='right',
                                    tickvals=[0, 1],
                                    ticktext=['OFF', 'ON']
                                )
                    
                    fig.update_layout(**layout_config)
                    
                    # Ajouter des fonctionnalit√©s interactives suppl√©mentaires
                    fig.update_layout(
                        # Configuration pour interactions de type TradingView
                        dragmode='zoom',
                        selectdirection='h',  # 'h' pour horizontal
                        showlegend=True,
                    )
                    
                    # Configurer les interactions
                    fig.update_xaxes(
                        rangeslider_visible=False,  # Pas de rangeslider pour √©viter l'encombrement
                        showspikes=True,
                        spikecolor="gray",
                        spikesnap="cursor",
                        spikemode="across",
                        spikethickness=1
                    )
                    
                    fig.update_yaxes(
                        showspikes=True,
                        spikecolor="gray",
                        spikethickness=1
                    )
                    
                    # Afficher le graphique avec configuration √©tendue
                    config = {
                        'displayModeBar': True,
                        'modeBarButtonsToAdd': ['drawline', 'drawopenpath', 'drawclosedpath', 'drawcircle', 'drawrect', 'eraseshape'],
                        'toImageButtonOptions': {
                            'format': 'png',
                            'filename': f'evolution_temporelle_{binary_display.lower().replace(" ", "_")}',
                            'height': 700,
                            'width': 1200,
                            'scale': 2
                        }
                    }
                    st.plotly_chart(fig, use_container_width=True, config=config)
                    
                    # Ajouter une l√©gende des couleurs pour r√©f√©rence
                    if binary_display == "Superpos√©es transparentes" and binary_metrics:
                        with st.expander("üé® Guide du syst√®me de couches"):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("**üìä Couche de fond (Donn√©es continues):**")
                                st.markdown("- <span style='color:#2E86AB'>**Temp√©rature Ambiante**</span> - Ligne pleine", unsafe_allow_html=True)
                                st.markdown("- <span style='color:#A23B72'>**Temp√©rature Ext√©rieure**</span> - Ligne pleine", unsafe_allow_html=True)
                                st.markdown("- <span style='color:#F18F01'>**Puissance IT**</span> - Ligne pleine", unsafe_allow_html=True)
                                st.markdown("- <span style='color:#C73E1D'>**Puissance G√©n√©rale**</span> - Ligne pleine", unsafe_allow_html=True)
                                st.markdown("- <span style='color:#FF6B6B'>**Puissance CLIM**</span> - Ligne pleine", unsafe_allow_html=True)
                            with col2:
                                st.markdown("**üîß Couche superpos√©e (√âtats binaires):**")
                                st.markdown("- <span style='color:#4ECDC4'>**CLIM A**</span> - Zones transparentes empil√©es", unsafe_allow_html=True)
                                st.markdown("- <span style='color:#45B7D1'>**CLIM B**</span> - Zones transparentes empil√©es", unsafe_allow_html=True)
                                st.markdown("- <span style='color:#96CEB4'>**CLIM C**</span> - Zones transparentes empil√©es", unsafe_allow_html=True)
                                st.markdown("- <span style='color:#FECA57'>**CLIM D**</span> - Zones transparentes empil√©es", unsafe_allow_html=True)
                                st.markdown("- <span style='color:#6C5CE7'>**Porte**</span> - Zones transparentes empil√©es", unsafe_allow_html=True)
                                st.markdown("\n**üí° Les zones color√©es = ON, transparent = OFF**")
            else:
                st.info("Veuillez s√©lectionner au moins une m√©trique √† afficher.")
        else:
            st.warning("Aucune donn√©e disponible pour la p√©riode s√©lectionn√©e.")
    else:
        st.error("Aucune donn√©e disponible.")

# 2. ANALYSE TEMPORELLE INTERACTIVE
with tab2:
    st.header("üìà Analyse temporelle interactive")
    
    # Display current unified period
    st.info(f"üìÖ P√©riode s√©lectionn√©e: {start_date.strftime('%Y-%m-%d %H:%M')} - {end_date.strftime('%Y-%m-%d %H:%M')}")
    
    # S√©lection des donn√©es
    # Multi-s√©lection des donn√©es √† afficher
    available_metrics = {
        'Temp_Ambiante': 'üå°Ô∏è Temp√©rature Ambiante (¬∞C)',
        'Temp_Exterieure': 'üå§Ô∏è Temp√©rature Ext√©rieure (¬∞C)',
        'Puissance_IT': 'üíª Puissance IT (kW)',
        'Puissance_Generale': '‚ö° Puissance G√©n√©rale (kW)',
        'Puissance_CLIM': '‚ùÑÔ∏è Puissance CLIM (kW)',
        'CLIM_A_Status': '‚ùÑÔ∏è √âtat CLIM A',
        'CLIM_B_Status': '‚ùÑÔ∏è √âtat CLIM B',
        'CLIM_C_Status': '‚ùÑÔ∏è √âtat CLIM C',
        'CLIM_D_Status': '‚ùÑÔ∏è √âtat CLIM D',
        'Porte_Status': 'üö™ √âtat Porte'
    }
    
    # Filtrer les m√©triques disponibles
    available_cols = [col for col in available_metrics.keys() if col in filtered_merged_data.columns]
    
    selected_metrics = st.multiselect(
        "S√©lectionner les donn√©es √† afficher:",
        available_cols,
        default=available_cols[:3] if len(available_cols) >= 3 else available_cols,
        format_func=lambda x: available_metrics[x]
    )
    
    # Use unified filtered data
    if selected_metrics and not filtered_merged_data.empty:
        filtered_data = filtered_merged_data
        
        # Cr√©ation du graphique interactif
        fig = make_subplots(
            rows=len(selected_metrics),
            cols=1,
            shared_xaxes=True,
            vertical_spacing=0.05,
            subplot_titles=[available_metrics[m] for m in selected_metrics]
        )
        
        colors = px.colors.qualitative.Set3
        fill_colors = [
            'rgba(141, 211, 199, 0.3)',
            'rgba(255, 255, 179, 0.3)',
            'rgba(190, 186, 218, 0.3)',
            'rgba(251, 128, 114, 0.3)',
            'rgba(128, 177, 211, 0.3)',
            'rgba(253, 180, 98, 0.3)',
            'rgba(179, 222, 105, 0.3)',
            'rgba(252, 205, 229, 0.3)',
            'rgba(217, 217, 217, 0.3)',
            'rgba(188, 128, 189, 0.3)'
        ]
        
        for idx, metric in enumerate(selected_metrics):
            # D√©terminer le type de graphique selon la m√©trique
            if 'Status' in metric:
                # Pour les statuts, utiliser un graphique en escalier
                fig.add_trace(
                    go.Scatter(
                        x=filtered_data['Timestamp'],
                        y=filtered_data[metric],
                        name=available_metrics[metric],
                        mode='lines',
                        line=dict(shape='hv', color=colors[idx % len(colors)]),
                        fill='tozeroy',
                        fillcolor=fill_colors[idx % len(fill_colors)]
                    ),
                    row=idx+1, col=1
                )
            else:
                # Pour les m√©triques continues
                fig.add_trace(
                    go.Scatter(
                        x=filtered_data['Timestamp'],
                        y=filtered_data[metric],
                        name=available_metrics[metric],
                        mode='lines',
                        line=dict(color=colors[idx % len(colors)], width=2),
                        hovertemplate='%{y:.2f}<br>%{x}<extra></extra>'
                    ),
                    row=idx+1, col=1
                )
            
            # Mise √† jour des axes Y
            fig.update_yaxes(title_text=metric.split('_')[0], row=idx+1, col=1)
        
        # Mise √† jour de la mise en page
        fig.update_layout(
            height=200 * len(selected_metrics),
            showlegend=False,
            hovermode='x unified',
            margin=dict(l=50, r=50, t=50, b=50)
        )
        
        fig.update_xaxes(title_text="Date et heure", row=len(selected_metrics), col=1)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Options d'export
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            if st.button("üìä Exporter en PNG"):
                fig.write_image("export_analyse_temporelle.png")
                st.success("Graphique export√©!")
        
        with col2:
            if st.button("üìÑ Exporter en CSV"):
                export_data = filtered_data[['Timestamp'] + selected_metrics]
                export_data.to_csv("export_donnees.csv", index=False)
                st.success("Donn√©es export√©es!")
    
    # Profile Horaire Moyen Unifi√©
    st.subheader("üìä Profil Horaire Moyen Unifi√©")
    st.write("Visualisation comparative des profils horaires moyens pour Temp√©rature Ambiante, Puissance IT et Temp√©rature Ext√©rieure")
    
    if not filtered_merged_data.empty:
        # Prepare hourly data for the three metrics
        hourly_data = filtered_merged_data.copy()
        hourly_data['Heure'] = hourly_data['Timestamp'].dt.hour
        
        # Create figure with secondary y-axis
        fig = make_subplots(specs=[[{"secondary_y": True}]])
        
        # Temperature Ambiante
        if 'Temp_Ambiante' in hourly_data.columns:
            hourly_avg_ambiante = hourly_data.groupby('Heure')['Temp_Ambiante'].agg(['mean', 'std']).reset_index()
            
            # Add mean line
            fig.add_trace(
                go.Scatter(
                    x=hourly_avg_ambiante['Heure'],
                    y=hourly_avg_ambiante['mean'],
                    mode='lines+markers',
                    name='Temp√©rature Ambiante (¬∞C)',
                    line=dict(color='#FF6B6B', width=3),
                    marker=dict(size=8),
                    yaxis='y'
                ),
                secondary_y=False
            )
            
            # Add std band
            fig.add_trace(
                go.Scatter(
                    x=list(hourly_avg_ambiante['Heure']) + list(hourly_avg_ambiante['Heure'][::-1]),
                    y=list(hourly_avg_ambiante['mean'] + hourly_avg_ambiante['std']) + list((hourly_avg_ambiante['mean'] - hourly_avg_ambiante['std'])[::-1]),
                    fill='toself',
                    fillcolor='rgba(255,107,107,0.15)',
                    line=dict(color='rgba(255,255,255,0)'),
                    name='¬± √âcart-type Temp Ambiante',
                    showlegend=False,
                    yaxis='y'
                ),
                secondary_y=False
            )
        
        # Temperature Ext√©rieure
        if 'Temp_Exterieure' in hourly_data.columns:
            hourly_avg_ext = hourly_data.groupby('Heure')['Temp_Exterieure'].agg(['mean', 'std']).reset_index()
            
            # Add mean line
            fig.add_trace(
                go.Scatter(
                    x=hourly_avg_ext['Heure'],
                    y=hourly_avg_ext['mean'],
                    mode='lines+markers',
                    name='Temp√©rature Ext√©rieure (¬∞C)',
                    line=dict(color='#4ECDC4', width=3),
                    marker=dict(size=8),
                    yaxis='y'
                ),
                secondary_y=False
            )
            
            # Add std band
            fig.add_trace(
                go.Scatter(
                    x=list(hourly_avg_ext['Heure']) + list(hourly_avg_ext['Heure'][::-1]),
                    y=list(hourly_avg_ext['mean'] + hourly_avg_ext['std']) + list((hourly_avg_ext['mean'] - hourly_avg_ext['std'])[::-1]),
                    fill='toself',
                    fillcolor='rgba(78,205,196,0.15)',
                    line=dict(color='rgba(255,255,255,0)'),
                    name='¬± √âcart-type Temp Ext√©rieure',
                    showlegend=False,
                    yaxis='y'
                ),
                secondary_y=False
            )
        
        # Puissance IT (on secondary y-axis)
        if 'Puissance_IT' in hourly_data.columns:
            hourly_avg_it = hourly_data.groupby('Heure')['Puissance_IT'].agg(['mean', 'std']).reset_index()
            
            # Add mean line
            fig.add_trace(
                go.Scatter(
                    x=hourly_avg_it['Heure'],
                    y=hourly_avg_it['mean'],
                    mode='lines+markers',
                    name='Puissance IT (kW)',
                    line=dict(color='#6C5CE7', width=3, dash='dot'),
                    marker=dict(size=8, symbol='square'),
                    yaxis='y2'
                ),
                secondary_y=True
            )
            
            # Add std band
            fig.add_trace(
                go.Scatter(
                    x=list(hourly_avg_it['Heure']) + list(hourly_avg_it['Heure'][::-1]),
                    y=list(hourly_avg_it['mean'] + hourly_avg_it['std']) + list((hourly_avg_it['mean'] - hourly_avg_it['std'])[::-1]),
                    fill='toself',
                    fillcolor='rgba(108,92,231,0.15)',
                    line=dict(color='rgba(255,255,255,0)'),
                    name='¬± √âcart-type Puissance IT',
                    showlegend=False,
                    yaxis='y2'
                ),
                secondary_y=True
            )
        
        # Update layout
        fig.update_xaxes(
            title_text="Heure de la journ√©e",
            tickmode='linear',
            tick0=0,
            dtick=2,
            range=[-0.5, 23.5]
        )
        
        fig.update_yaxes(
            title_text="Temp√©rature (¬∞C)",
            secondary_y=False,
            gridcolor='rgba(128,128,128,0.2)'
        )
        
        fig.update_yaxes(
            title_text="Puissance IT (kW)",
            secondary_y=True,
            gridcolor='rgba(128,128,128,0.1)'
        )
        
        fig.update_layout(
            title="Profil Horaire Moyen - Vue Comparative",
            height=500,
            hovermode='x unified',
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=-0.2,
                xanchor="center",
                x=0.5
            ),
            template='plotly_white',
            margin=dict(l=50, r=50, t=50, b=100)
        )
        
        # Add grid
        fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='rgba(128,128,128,0.2)')
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Add insights
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if 'Temp_Ambiante' in hourly_data.columns:
                peak_hour_amb = hourly_avg_ambiante.loc[hourly_avg_ambiante['mean'].idxmax(), 'Heure']
                peak_temp_amb = hourly_avg_ambiante['mean'].max()
                st.metric(
                    "üå°Ô∏è Pic Temp Ambiante",
                    f"{peak_temp_amb:.1f}¬∞C",
                    f"√† {int(peak_hour_amb)}h"
                )
        
        with col2:
            if 'Puissance_IT' in hourly_data.columns:
                peak_hour_it = hourly_avg_it.loc[hourly_avg_it['mean'].idxmax(), 'Heure']
                peak_power_it = hourly_avg_it['mean'].max()
                st.metric(
                    "üíª Pic Puissance IT",
                    f"{peak_power_it:.1f} kW",
                    f"√† {int(peak_hour_it)}h"
                )
        
        with col3:
            if 'Temp_Exterieure' in hourly_data.columns:
                peak_hour_ext = hourly_avg_ext.loc[hourly_avg_ext['mean'].idxmax(), 'Heure']
                peak_temp_ext = hourly_avg_ext['mean'].max()
                st.metric(
                    "üå§Ô∏è Pic Temp Ext√©rieure",
                    f"{peak_temp_ext:.1f}¬∞C",
                    f"√† {int(peak_hour_ext)}h"
                )

# 3. ANALYSES EDA
with tab3:
    st.header("üî¨ Analyses exploratoires (EDA)")
    
    # Display current unified period
    st.info(f"üìÖ P√©riode s√©lectionn√©e: {start_date.strftime('%Y-%m-%d %H:%M')} - {end_date.strftime('%Y-%m-%d %H:%M')}")
    
    if not filtered_merged_data.empty and 'Timestamp' in filtered_merged_data.columns:
        # S√©lection des m√©triques (multi-s√©lection)
        numeric_cols = ['Temp_Ambiante', 'Temp_Exterieure', 'Puissance_IT', 
                       'Puissance_Generale', 'Puissance_CLIM']
        available_numeric = [col for col in numeric_cols if col in filtered_merged_data.columns]
        
        metric_labels = {
            'Temp_Ambiante': 'üå°Ô∏è Temp√©rature Ambiante',
            'Temp_Exterieure': 'üå§Ô∏è Temp√©rature Ext√©rieure',
            'Puissance_IT': 'üíª Puissance IT',
            'Puissance_Generale': '‚ö° Puissance G√©n√©rale',
            'Puissance_CLIM': '‚ùÑÔ∏è Puissance CLIM'
        }
        
        selected_metrics = st.multiselect(
            "S√©lectionner les m√©triques √† analyser:",
            available_numeric,
            default=[available_numeric[0]] if available_numeric else [],
            format_func=lambda x: metric_labels.get(x, x)
        )
        
        # Use unified filtered data
        filtered_data = filtered_merged_data
    
        
        # Afficher les analyses pour chaque m√©trique s√©lectionn√©e
        if selected_metrics and not filtered_data.empty:
            for metric in selected_metrics:
                st.markdown("---")
                st.subheader(f"üìä Analyse compl√®te: {metric_labels.get(metric, metric)}")
                
                # V√©rifier la disponibilit√© des donn√©es
                metric_data = filtered_data[metric].dropna()
                if len(metric_data) == 0:
                    st.warning(f"Aucune donn√©e disponible pour {metric_labels.get(metric, metric)} dans la p√©riode s√©lectionn√©e.")
                    continue
                
                # 1. STATISTIQUES G√âN√âRALES
                with st.expander(f"üìà Statistiques et informations - {metric_labels.get(metric, metric)}", expanded=True):
                    col1, col2 = st.columns([1, 2])
                    
                    with col1:
                        st.markdown("**Informations g√©n√©rales**")
                        total_points = len(filtered_data)
                        valid_points = len(metric_data)
                        missing_points = total_points - valid_points
                        
                        st.metric("Points totaux", f"{total_points:,}")
                        st.metric("Points valides", f"{valid_points:,}")
                        st.metric("Donn√©es manquantes", f"{missing_points:,} ({missing_points/total_points*100:.1f}%)")
                    
                    with col2:
                        st.markdown("**Statistiques descriptives**")
                        stats_data = {
                            'Statistique': ['Minimum', 'Maximum', 'Moyenne', 'M√©diane', '√âcart-type', 'Asym√©trie', 'Aplatissement'],
                            'Valeur': [
                                f"{metric_data.min():.2f}",
                                f"{metric_data.max():.2f}",
                                f"{metric_data.mean():.2f}",
                                f"{metric_data.median():.2f}",
                                f"{metric_data.std():.2f}",
                                f"{stats.skew(metric_data):.2f}",
                                f"{stats.kurtosis(metric_data):.2f}"
                            ]
                        }
                        st.dataframe(pd.DataFrame(stats_data), hide_index=True, use_container_width=True)
                
                # 2. VISUALISATIONS DE DISTRIBUTION
                st.markdown(f"#### üìä Distribution - {metric_labels.get(metric, metric)}")
                col1, col2 = st.columns(2)
                
                with col1:
                    # Histogramme avec KDE
                    fig_hist = go.Figure()
                    
                    # Histogramme
                    fig_hist.add_trace(go.Histogram(
                        x=metric_data,
                        name='Fr√©quence',
                        nbinsx=30,
                        marker_color='lightblue',
                        opacity=0.7
                    ))
                    
                    # KDE
                    kde_x = np.linspace(metric_data.min(), metric_data.max(), 100)
                    kde = stats.gaussian_kde(metric_data)
                    kde_y = kde(kde_x) * len(metric_data) * (metric_data.max() - metric_data.min()) / 30
                    
                    fig_hist.add_trace(go.Scatter(
                        x=kde_x,
                        y=kde_y,
                        mode='lines',
                        name='Densit√© (KDE)',
                        line=dict(color='red', width=2),
                        yaxis='y2'
                    ))
                    
                    fig_hist.update_layout(
                        title=f"Histogramme - {metric}",
                        xaxis_title=metric,
                        yaxis_title="Fr√©quence",
                        yaxis2=dict(overlaying='y', side='right', title='Densit√©'),
                        height=400,
                        showlegend=True
                    )
                    
                    st.plotly_chart(fig_hist, use_container_width=True)
                
                with col2:
                    # Bo√Æte √† moustaches
                    fig_box = go.Figure()
                    fig_box.add_trace(go.Box(
                        y=metric_data,
                        name=metric,
                        boxpoints='outliers',
                        marker_color='lightcoral',
                        line_color='darkred'
                    ))
                    
                    fig_box.update_layout(
                        title=f"Bo√Æte √† moustaches - {metric}",
                        yaxis_title=metric,
                        height=400
                    )
                    
                    st.plotly_chart(fig_box, use_container_width=True)
                    
                    # Statistiques des quartiles
                    q1 = metric_data.quantile(0.25)
                    q3 = metric_data.quantile(0.75)
                    iqr = q3 - q1
                    
                    st.caption("**Quartiles:**")
                    st.caption(f"Q1 (25%): {q1:.2f} | Q3 (75%): {q3:.2f} | IQR: {iqr:.2f}")
                
                # 3. ANALYSES TEMPORELLES
                st.markdown(f"#### üìà Analyses temporelles - {metric_labels.get(metric, metric)}")
                
                # S√©rie temporelle brute
                with st.expander("S√©rie temporelle compl√®te", expanded=True):
                    fig_ts = go.Figure()
                    fig_ts.add_trace(go.Scatter(
                        x=filtered_data['Timestamp'],
                        y=filtered_data[metric],
                        mode='lines',
                        name=metric,
                        line=dict(color='green', width=1)
                    ))
                    
                    fig_ts.update_layout(
                        title=f"√âvolution temporelle - {metric}",
                        xaxis_title="Date et heure",
                        yaxis_title=metric,
                        height=400,
                        hovermode='x unified'
                    )
                    
                    st.plotly_chart(fig_ts, use_container_width=True)
                
                # Moyennes journali√®res et profil horaire c√¥te √† c√¥te
                col1, col2 = st.columns(2)
                
                with col1:
                    # Moyennes journali√®res
                    daily_data = filtered_data.copy()
                    daily_data['Date'] = daily_data['Timestamp'].dt.date
                    daily_avg = daily_data.groupby('Date')[metric].mean().reset_index()
                    
                    if len(daily_avg) > 0:
                        fig_daily = go.Figure()
                        fig_daily.add_trace(go.Scatter(
                            x=daily_avg['Date'],
                            y=daily_avg[metric],
                            mode='lines+markers',
                            name='Moyenne journali√®re',
                            line=dict(color='blue', width=2),
                            marker=dict(size=6)
                        ))
                        
                        fig_daily.update_layout(
                            title=f"Moyennes journali√®res - {metric}",
                            xaxis_title="Date",
                            yaxis_title=f"Moyenne {metric}",
                            height=350
                        )
                        
                        st.plotly_chart(fig_daily, use_container_width=True)
                
                with col2:
                    # Profil horaire
                    hourly_data = filtered_data.copy()
                    hourly_data['Heure'] = hourly_data['Timestamp'].dt.hour
                    hourly_avg = hourly_data.groupby('Heure')[metric].agg(['mean', 'std']).reset_index()
                    
                    if len(hourly_avg) > 0:
                        fig_hourly = go.Figure()
                        
                        # Moyenne
                        fig_hourly.add_trace(go.Scatter(
                            x=hourly_avg['Heure'],
                            y=hourly_avg['mean'],
                            mode='lines+markers',
                            name='Moyenne',
                            line=dict(color='darkblue', width=3),
                            marker=dict(size=8)
                        ))
                        
                        # Bande d'√©cart-type
                        fig_hourly.add_trace(go.Scatter(
                            x=list(hourly_avg['Heure']) + list(hourly_avg['Heure'][::-1]),
                            y=list(hourly_avg['mean'] + hourly_avg['std']) + list((hourly_avg['mean'] - hourly_avg['std'])[::-1]),
                            fill='toself',
                            fillcolor='rgba(0,100,250,0.2)',
                            line=dict(color='rgba(255,255,255,0)'),
                            name='¬± √âcart-type',
                            showlegend=True
                        ))
                        
                        fig_hourly.update_layout(
                            title=f"Profil horaire moyen - {metric}",
                            xaxis_title="Heure",
                            yaxis_title=metric,
                            height=350,
                            xaxis=dict(tickmode='linear', tick0=0, dtick=2)
                        )
                        
                        st.plotly_chart(fig_hourly, use_container_width=True)
        
        elif not selected_metrics:
            st.info("üëÜ Veuillez s√©lectionner au moins une m√©trique √† analyser.")
        else:
            st.warning("Aucune donn√©e disponible pour la p√©riode s√©lectionn√©e.")
    
    else:
        st.error("Aucune donn√©e disponible.")

# 4. ANALYSE CLIM
with tab4:
    st.header("‚ùÑÔ∏è Analyse de l'impact des CLIMs sur la temp√©rature")
    st.info(f"üìÖ P√©riode s√©lectionn√©e: {start_date.strftime('%Y-%m-%d %H:%M')} - {end_date.strftime('%Y-%m-%d %H:%M')}")
    
    # Pr√©parer les donn√©es CLIM
    clim_columns = [col for col in filtered_merged_data.columns if 'CLIM' in col and 'Status' in col]
    
    if clim_columns and 'Temp_Ambiante' in filtered_merged_data.columns:
        # Info sur les donn√©es disponibles
        st.info(f"**CLIMs d√©tect√©es:** {', '.join(clim_columns)}")
        
        # V√©rifier l'√©tat des CLIMs
        clim_status_summary = []
        for clim in clim_columns:
            if clim in filtered_merged_data.columns:
                total_points = len(filtered_merged_data)
                on_points = (filtered_merged_data[clim] == 1).sum()
                off_points = (filtered_merged_data[clim] == 0).sum()
                clim_status_summary.append({
                    'CLIM': clim,
                    'Total Points': total_points,
                    'ON': on_points,
                    'OFF': off_points,
                    '% ON': (on_points / total_points * 100) if total_points > 0 else 0
                })
        
        if clim_status_summary:
            df_clim_summary = pd.DataFrame(clim_status_summary)
            st.dataframe(df_clim_summary.style.format({
                '% ON': '{:.1f}%'
            }), use_container_width=True)
        
        # Analyse de la temp√©rature apr√®s arr√™t CLIM
        st.subheader("üìâ √âvolution de la temp√©rature apr√®s arr√™t des CLIMs")
        
        # Param√®tres
        col1, col2 = st.columns(2)
        with col1:
            minutes_after = st.slider("Minutes apr√®s l'arr√™t", 5, 60, 30, 5)
        with col2:
            selected_clim = st.selectbox("S√©lectionner un CLIM", clim_columns)
        
        # D√©tecter les arr√™ts de CLIM (passage de 1 √† 0)
        filtered_merged_data['CLIM_Stop'] = (filtered_merged_data[selected_clim].shift(1) == 1) & (filtered_merged_data[selected_clim] == 0)
        
        # Points d'arr√™t
        stop_points = filtered_merged_data[filtered_merged_data['CLIM_Stop']]['Timestamp'].tolist()
        
        # Debug info
        with st.expander("üîç Informations de d√©bogage"):
            st.write(f"Total de points de donn√©es: {len(filtered_merged_data)}")
            st.write(f"Points avec temp√©rature valide: {filtered_merged_data['Temp_Ambiante'].notna().sum()}")
            st.write(f"Valeurs uniques de {selected_clim}: {filtered_merged_data[selected_clim].value_counts().to_dict()}")
            st.write(f"Transitions d√©tect√©es (1‚Üí0): {len(stop_points)}")
            if stop_points:
                st.write(f"Premiers arr√™ts: {[t.strftime('%Y-%m-%d %H:%M') for t in stop_points[:5]]}")
        
        if stop_points:
            # Analyser chaque arr√™t
            temp_changes = []
            
            st.write(f"**{len(stop_points)} arr√™ts d√©tect√©s pour {selected_clim}**")
            st.write(f"**Analyse de tous les {len(stop_points)} arr√™ts...**")
            
            # Progress bar for large datasets
            progress_bar = st.progress(0)
            
            for i, stop_time in enumerate(stop_points):  # Analyser tous les √©v√©nements
                # Temp√©rature au moment de l'arr√™t
                temp_at_stop_idx = filtered_merged_data[filtered_merged_data['Timestamp'] <= stop_time]['Temp_Ambiante'].last_valid_index()
                
                if temp_at_stop_idx is not None:
                    temp_at_stop = filtered_merged_data.loc[temp_at_stop_idx, 'Temp_Ambiante']
                    
                    # Temp√©rature apr√®s X minutes
                    time_after = stop_time + timedelta(minutes=minutes_after)
                    after_mask = (filtered_merged_data['Timestamp'] > stop_time) & \
                                (filtered_merged_data['Timestamp'] <= time_after)
                    temps_after = filtered_merged_data[after_mask]['Temp_Ambiante'].dropna()
                    
                    if len(temps_after) > 0:
                        # Prendre la derni√®re temp√©rature dans la fen√™tre
                        temp_final = temps_after.iloc[-1]
                        temp_change = temp_final - temp_at_stop
                        
                        temp_changes.append({
                            'Timestamp': stop_time,
                            'Temp_Initial': temp_at_stop,
                            'Temp_Final': temp_final,
                            'Delta_Temp': temp_change,
                            'CLIM': selected_clim,
                            'Duration_min': minutes_after,
                            'Num_Points': len(temps_after)
                        })
                    else:
                        # M√™me si pas de donn√©es apr√®s, enregistrer ce qu'on a
                        temp_changes.append({
                            'Timestamp': stop_time,
                            'Temp_Initial': temp_at_stop,
                            'Temp_Final': temp_at_stop,  # Pas de changement
                            'Delta_Temp': 0.0,
                            'CLIM': selected_clim,
                            'Duration_min': minutes_after,
                            'Num_Points': 0
                        })
                
                # Update progress bar
                progress_bar.progress((i + 1) / len(stop_points))
            
            # Clear progress bar
            progress_bar.empty()
            
            st.write(f"**Cycles valides trouv√©s:** {len(temp_changes)}")
            
            if temp_changes:
                # Graphique des changements de temp√©rature
                df_changes = pd.DataFrame(temp_changes)
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=df_changes.index,
                    y=df_changes['Delta_Temp'],
                    mode='markers',
                    marker=dict(
                        size=10,
                        color=df_changes['Delta_Temp'],
                        colorscale='RdYlBu_r',
                        showscale=True,
                        colorbar=dict(title="ŒîT (¬∞C)")
                    ),
                    text=[f"Arr√™t: {t.strftime('%Y-%m-%d %H:%M')}<br>ŒîT: {d:.2f}¬∞C" 
                          for t, d in zip(df_changes['Timestamp'], df_changes['Delta_Temp'])],
                    hovertemplate='%{text}<extra></extra>'
                ))
                
                # Ligne de r√©f√©rence √† z√©ro
                fig.add_hline(y=0, line_dash="dash", line_color="gray")
                
                # Ligne de tendance moyenne
                avg_change = df_changes['Delta_Temp'].mean()
                fig.add_hline(y=avg_change, line_dash="solid", line_color="red",
                            annotation_text=f"Moyenne: {avg_change:.2f}¬∞C")
                
                fig.update_layout(
                    title=f"Changement de temp√©rature {minutes_after} min apr√®s arr√™t - {selected_clim}",
                    xaxis_title="√âv√©nement d'arr√™t",
                    yaxis_title="Changement de temp√©rature (¬∞C)",
                    height=500
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Tableau r√©capitulatif d√©taill√©
                st.subheader("üìä R√©sum√© statistique complet")
                
                # Premi√®re ligne de m√©triques
                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("ŒîT Moyen", f"{df_changes['Delta_Temp'].mean():.2f}¬∞C")
                with col2:
                    st.metric("ŒîT M√©dian", f"{df_changes['Delta_Temp'].median():.2f}¬∞C")
                with col3:
                    st.metric("ŒîT Min", f"{df_changes['Delta_Temp'].min():.2f}¬∞C")
                with col4:
                    st.metric("ŒîT Max", f"{df_changes['Delta_Temp'].max():.2f}¬∞C")
                with col5:
                    st.metric("√âcart-type", f"{df_changes['Delta_Temp'].std():.2f}¬∞C")
                
                # Deuxi√®me ligne de m√©triques
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Amplitude", f"{df_changes['Delta_Temp'].max() - df_changes['Delta_Temp'].min():.2f}¬∞C")
                with col2:
                    positive_changes = df_changes[df_changes['Delta_Temp'] > 0]
                    st.metric("Augmentations", f"{len(positive_changes)} ({len(positive_changes)/len(df_changes)*100:.1f}%)")
                with col3:
                    negative_changes = df_changes[df_changes['Delta_Temp'] < 0]
                    st.metric("Diminutions", f"{len(negative_changes)} ({len(negative_changes)/len(df_changes)*100:.1f}%)")
                with col4:
                    zero_changes = df_changes[df_changes['Delta_Temp'] == 0]
                    st.metric("Sans changement", f"{len(zero_changes)} ({len(zero_changes)/len(df_changes)*100:.1f}%)")
                
                # Tableau d√©taill√© de tous les √©v√©nements
                st.subheader("üìã D√©tail de tous les arr√™ts CLIM")
                
                # Pr√©parer les donn√©es pour l'affichage
                display_df = df_changes.copy()
                display_df['Timestamp'] = display_df['Timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')
                display_df['Temp_Initial'] = display_df['Temp_Initial'].round(2)
                display_df['Temp_Final'] = display_df['Temp_Final'].round(2)
                display_df['Delta_Temp'] = display_df['Delta_Temp'].round(2)
                
                # Ajouter une colonne pour l'index
                display_df.insert(0, 'N¬∞', range(1, len(display_df) + 1))
                
                # Renommer les colonnes pour l'affichage
                display_df = display_df.rename(columns={
                    'Timestamp': 'Date/Heure arr√™t',
                    'Temp_Initial': 'T¬∞ initiale (¬∞C)',
                    'Temp_Final': f'T¬∞ apr√®s {minutes_after}min (¬∞C)',
                    'Delta_Temp': 'ŒîT (¬∞C)',
                    'Num_Points': 'Points de donn√©es'
                })
                
                # S√©lectionner les colonnes √† afficher
                columns_to_display = ['N¬∞', 'Date/Heure arr√™t', 'T¬∞ initiale (¬∞C)', 
                                     f'T¬∞ apr√®s {minutes_after}min (¬∞C)', 'ŒîT (¬∞C)', 'Points de donn√©es']
                
                # Utiliser un expander si il y a beaucoup d'√©v√©nements
                if len(display_df) > 20:
                    with st.expander(f"Voir tous les {len(display_df)} √©v√©nements"):
                        st.dataframe(
                            display_df[columns_to_display],
                            use_container_width=True,
                            hide_index=True
                        )
                else:
                    st.dataframe(
                        display_df[columns_to_display],
                        use_container_width=True,
                        hide_index=True
                    )
                
                # Bouton pour t√©l√©charger les donn√©es
                csv = display_df[columns_to_display].to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="üì• T√©l√©charger les donn√©es en CSV",
                    data=csv,
                    file_name=f"analyse_arrets_{selected_clim}_{minutes_after}min.csv",
                    mime="text/csv"
                )
                
                # Visualisations suppl√©mentaires des distributions
                st.subheader("üìä Distribution des changements de temp√©rature")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # Histogramme des changements de temp√©rature
                    fig_hist = go.Figure()
                    fig_hist.add_trace(go.Histogram(
                        x=df_changes['Delta_Temp'],
                        nbinsx=20,
                        name='Distribution',
                        marker_color='lightblue',
                        opacity=0.7
                    ))
                    
                    # Ajouter une ligne verticale pour la moyenne
                    mean_delta = df_changes['Delta_Temp'].mean()
                    fig_hist.add_vline(x=mean_delta, line_dash="dash", line_color="red",
                                      annotation_text=f"Moyenne: {mean_delta:.2f}¬∞C")
                    
                    # Ajouter une ligne verticale pour la m√©diane
                    median_delta = df_changes['Delta_Temp'].median()
                    fig_hist.add_vline(x=median_delta, line_dash="dot", line_color="green",
                                      annotation_text=f"M√©diane: {median_delta:.2f}¬∞C")
                    
                    fig_hist.update_layout(
                        title="Histogramme des ŒîT",
                        xaxis_title="Changement de temp√©rature (¬∞C)",
                        yaxis_title="Fr√©quence",
                        showlegend=False,
                        height=400
                    )
                    st.plotly_chart(fig_hist, use_container_width=True)
                
                with col2:
                    # Box plot des changements de temp√©rature
                    fig_box = go.Figure()
                    fig_box.add_trace(go.Box(
                        y=df_changes['Delta_Temp'],
                        name='ŒîT',
                        boxpoints='outliers',
                        marker_color='lightgreen',
                        line_color='darkgreen'
                    ))
                    
                    fig_box.update_layout(
                        title="Box Plot des ŒîT",
                        yaxis_title="Changement de temp√©rature (¬∞C)",
                        showlegend=False,
                        height=400
                    )
                    
                    # Ajouter des annotations pour les quartiles
                    q1 = df_changes['Delta_Temp'].quantile(0.25)
                    q3 = df_changes['Delta_Temp'].quantile(0.75)
                    iqr = q3 - q1
                    
                    fig_box.add_annotation(
                        x=0.5, y=q1,
                        text=f"Q1: {q1:.2f}¬∞C",
                        showarrow=True,
                        arrowhead=2,
                        xref="paper"
                    )
                    
                    fig_box.add_annotation(
                        x=0.5, y=q3,
                        text=f"Q3: {q3:.2f}¬∞C",
                        showarrow=True,
                        arrowhead=2,
                        xref="paper"
                    )
                    
                    st.plotly_chart(fig_box, use_container_width=True)
                
                # Graphique temporel
                st.subheader("üìà √âvolution temporelle de la temp√©rature")
                
                # S√©lectionner un √©v√©nement √† visualiser
                event_idx = st.selectbox(
                    "S√©lectionner un arr√™t √† visualiser",
                    range(len(df_changes)),
                    format_func=lambda x: f"Arr√™t {x+1} - {df_changes.iloc[x]['Timestamp'].strftime('%Y-%m-%d %H:%M')} (ŒîT: {df_changes.iloc[x]['Delta_Temp']:.2f}¬∞C)"
                )
                
                if event_idx is not None:
                    selected_event = df_changes.iloc[event_idx]
                    stop_time = selected_event['Timestamp']
                    
                    # R√©cup√©rer les donn√©es pour visualiser
                    viz_start = stop_time - timedelta(minutes=15)
                    viz_end = stop_time + timedelta(minutes=minutes_after + 10)
                    
                    viz_mask = (filtered_merged_data['Timestamp'] >= viz_start) & \
                              (filtered_merged_data['Timestamp'] <= viz_end)
                    viz_data = filtered_merged_data[viz_mask].copy()
                    
                    if len(viz_data) > 0:
                        fig_timeline = go.Figure()
                        
                        # Temp√©rature
                        fig_timeline.add_trace(go.Scatter(
                            x=viz_data['Timestamp'],
                            y=viz_data['Temp_Ambiante'],
                            mode='lines',
                            name='Temp√©rature',
                            line=dict(color='red', width=2)
                        ))
                        
                        # √âtat du CLIM
                        fig_timeline.add_trace(go.Scatter(
                            x=viz_data['Timestamp'],
                            y=viz_data[selected_clim] * viz_data['Temp_Ambiante'].max() * 0.95,
                            mode='lines',
                            name=f'{selected_clim} (ON/OFF)',
                            line=dict(color='blue', width=2, dash='dash'),
                            yaxis='y2'
                        ))
                        
                        # Marquer l'arr√™t avec add_shape au lieu de add_vline
                        fig_timeline.add_shape(
                            type="line",
                            x0=stop_time, x1=stop_time,
                            y0=0, y1=1,
                            yref="paper",
                            line=dict(color="green", width=2, dash="dash")
                        )
                        fig_timeline.add_annotation(
                            x=stop_time,
                            y=1.05,
                            yref="paper",
                            text="Arr√™t CLIM",
                            showarrow=False
                        )
                        
                        # Marquer la fin de la fen√™tre d'analyse
                        end_time = stop_time + timedelta(minutes=minutes_after)
                        fig_timeline.add_shape(
                            type="line",
                            x0=end_time, x1=end_time,
                            y0=0, y1=1,
                            yref="paper",
                            line=dict(color="orange", width=1, dash="dot")
                        )
                        fig_timeline.add_annotation(
                            x=end_time,
                            y=1.05,
                            yref="paper",
                            text=f"+{minutes_after} min",
                            showarrow=False
                        )
                        
                        fig_timeline.update_layout(
                            title=f"√âvolution autour de l'arr√™t du {stop_time.strftime('%Y-%m-%d %H:%M')}",
                            xaxis_title="Temps",
                            yaxis_title="Temp√©rature (¬∞C)",
                            yaxis2=dict(
                                title="√âtat CLIM",
                                overlaying='y',
                                side='right',
                                showticklabels=False
                            ),
                            height=400
                        )
                        
                        st.plotly_chart(fig_timeline, use_container_width=True)
                
                # Tableau d√©taill√©
                with st.expander("üìã Voir le d√©tail des √©v√©nements"):
                    st.dataframe(
                        df_changes.style.format({
                            'Temp_Initial': '{:.1f}¬∞C',
                            'Temp_Final': '{:.1f}¬∞C',
                            'Delta_Temp': '{:.2f}¬∞C'
                        })
                    )
            else:
                st.info(f"Aucun changement de temp√©rature mesur√© apr√®s les arr√™ts de {selected_clim}.")
        else:
            st.warning(f"Aucun arr√™t d√©tect√© pour {selected_clim} dans la p√©riode s√©lectionn√©e.")

# 5. INCIDENT LENS
with tab5:
    st.header("üö™ Analyse de l'impact de l'ouverture de porte")
    
    # Explication d'un cycle
    st.info("üí° **Qu'est-ce qu'un cycle ?** Un cycle correspond √† une s√©quence compl√®te d'ouverture et de fermeture de la porte. Il commence quand la porte passe de l'√©tat ferm√© √† ouvert, et se termine quand elle revient √† l'√©tat ferm√©. L'analyse suit l'√©volution de la temp√©rature pendant chaque cycle.")
    
    if 'Porte_Status' in filtered_merged_data.columns and 'Temp_Ambiante' in merged_data.columns:
        # Informations sur les donn√©es de porte
        st.subheader("üìä √âtat actuel des donn√©es de porte")
        
        porte_data_raw = filtered_merged_data[['Timestamp', 'Porte_Status', 'Temp_Ambiante']].copy()
        
        # Statistiques des donn√©es de porte
        open_records = porte_data_raw['Porte_Status'].notna().sum()
        st.metric("√âv√©nements d'ouverture", open_records)
        
        # Afficher un √©chantillon des donn√©es de porte
        st.subheader("üîç √âchantillon des √©v√©nements d'ouverture")
        door_events = porte_data_raw[porte_data_raw['Porte_Status'].notna()].copy()
        if not door_events.empty:
            st.dataframe(door_events.head(20), use_container_width=True)
            
            # Debug: Afficher les donn√©es brutes de porte avant traitement
            with st.expander("üîç Debug - Donn√©es de porte brutes (non-NaN uniquement)"):
                st.write(f"Nombre d'entr√©es non-NaN: {len(door_events)}")
                st.write(f"Valeurs uniques dans Porte_Status: {door_events['Porte_Status'].unique()}")
                st.write(f"Nombre de 1 (ouvert): {(door_events['Porte_Status'] == 1).sum()}")
                st.write(f"Nombre de 0 (ferm√©): {(door_events['Porte_Status'] == 0).sum()}")
                
                # Afficher les transitions dans les donn√©es brutes
                door_events_sorted = door_events.sort_values('Timestamp')
                door_events_sorted['Status_Change'] = door_events_sorted['Porte_Status'] != door_events_sorted['Porte_Status'].shift(1)
                transitions = door_events_sorted[door_events_sorted['Status_Change']]
                st.write(f"\nTransitions dans les donn√©es brutes: {len(transitions)}")
                if len(transitions) > 0:
                    st.dataframe(transitions[['Timestamp', 'Porte_Status']].head(20))
            
            # Fonction robuste de d√©tection des cycles de porte
            def detect_door_cycles(
                    df,
                    ts_col='Timestamp',
                    status_col='Porte_Status',
                    min_duration_sec=5,
                    max_duration_hours=24,
                    assume_close_at_end=True
                ):
                """
                D√©tecte les cycles d'ouverture/fermeture de porte.
                Approche simple: chaque "Ouverte" est appari√©e avec le prochain "Ferm√©".
                """
                # Copie pour √©viter de modifier l'original
                df_proc = df.copy()
                
                # 1. Sort by timestamp
                df_proc = df_proc.sort_values(ts_col).reset_index(drop=True)
                
                # 2. Convertir le statut en valeur num√©rique (1=ouvert, 0=ferm√©)
                if pd.api.types.is_string_dtype(df_proc[status_col]):
                    # G√©rer les statuts textuels en fran√ßais
                    clean_status = df_proc[status_col].str.strip().str.lower()
                    status_map = {
                        'ouverte': 1, 
                        'ouvert': 1, 
                        'ferm√©': 0, 
                        'ferme': 0,
                        'ferm√©e': 0
                    }
                    df_proc['state'] = clean_status.map(status_map)
                    df_proc['state'] = df_proc['state'].fillna(0)
                else:
                    # G√©rer les donn√©es num√©riques
                    df_proc['state'] = pd.to_numeric(df_proc[status_col], errors='coerce').fillna(0)
                
                df_proc['state'] = df_proc['state'].astype(int)
                
                # 3. Algorithme corrig√©: parcourir et apparier en sautant les ouvertures cons√©cutives
                cycles_list = []
                i = 0
                
                while i < len(df_proc):
                    # Chercher une ouverture
                    if df_proc.iloc[i]['state'] == 1 and pd.notna(df_proc.iloc[i][ts_col]):
                        open_time = df_proc.iloc[i][ts_col]
                        open_idx = i
                        
                        # Sauter toutes les ouvertures cons√©cutives
                        j = i + 1
                        while j < len(df_proc) and df_proc.iloc[j]['state'] == 1:
                            j += 1
                        
                        # Maintenant j pointe soit sur un 'Ferm√©' soit sur la fin des donn√©es
                        close_time = None
                        close_idx = None
                        
                        if j < len(df_proc) and df_proc.iloc[j]['state'] == 0:
                            close_time = df_proc.iloc[j][ts_col]
                            close_idx = j
                        
                        # Si pas de fermeture trouv√©e
                        if close_time is None or pd.isna(close_time):
                            if assume_close_at_end and pd.notna(open_time):
                                # Utiliser le dernier timestamp + 30 min ou la dur√©e max
                                last_time = df_proc.iloc[-1][ts_col]
                                if pd.notna(last_time):
                                    duration_to_last = (last_time - open_time).total_seconds()
                                    
                                    if duration_to_last > max_duration_hours * 3600:
                                        close_time = open_time + pd.Timedelta(hours=max_duration_hours)
                                    else:
                                        close_time = last_time + pd.Timedelta(minutes=30)
                                else:
                                    close_time = open_time + pd.Timedelta(minutes=30)
                                
                                # Cr√©er le cycle avec fermeture assum√©e
                                duration_sec = (close_time - open_time).total_seconds()
                                if duration_sec >= min_duration_sec:
                                    cycles_list.append({
                                        'open_ts': open_time,
                                        'close_ts': close_time,
                                        'duration_sec': duration_sec
                                    })
                            
                            # Passer au-del√† de toutes les ouvertures
                            i = j
                        else:
                            # Calculer la dur√©e
                            if pd.notna(open_time) and pd.notna(close_time):
                                duration_sec = (close_time - open_time).total_seconds()
                                
                                # Ajouter le cycle si la dur√©e est valide
                                if duration_sec >= min_duration_sec:
                                    cycles_list.append({
                                        'open_ts': open_time,
                                        'close_ts': close_time,
                                        'duration_sec': duration_sec
                                    })
                            
                            # Continuer apr√®s l'√©v√©nement de fermeture
                            i = close_idx + 1 if close_idx is not None else j
                    else:
                        i += 1
                
                # 4. Cr√©er le DataFrame des cycles
                cycles_df = pd.DataFrame(cycles_list)
                
                if len(cycles_df) == 0:
                    cycles_df = pd.DataFrame(columns=['open_ts', 'close_ts', 'duration_sec'])
                
                # 5. Debug info (optional)
                # print(f"[DEBUG] Total records: {len(df_proc)}, Open events: {(df_proc['state'] == 1).sum()}, Cycles found: {len(cycles_df)}")
                
                # Store debug info for display
                cycles_df.attrs['debug_df'] = df_proc[[ts_col, status_col, 'state']].head(100)
                
                return cycles_df
            
            # Param√®tres de d√©tection ajustables
            st.subheader("‚öôÔ∏è Param√®tres de d√©tection des cycles")
            col1, col2, col3 = st.columns(3)
            with col1:
                min_duration = st.number_input(
                    "Dur√©e min (secondes)", 
                    min_value=0, 
                    max_value=3600, 
                    value=0,
                    help="Dur√©e minimale pour qu'un cycle soit consid√©r√© valide (0 = pas de filtre)"
                )
            with col2:
                max_duration = st.number_input(
                    "Dur√©e max (heures)", 
                    min_value=1, 
                    max_value=48, 
                    value=24,
                    help="Dur√©e maximale d'un cycle"
                )
            with col3:
                detection_mode = st.selectbox(
                    "Mode de d√©tection",
                    ["Automatique", "√âv√©nements individuels", "Groupes stricts"],
                    help="Automatique: s'adapte aux donn√©es. √âv√©nements: chaque entr√©e 'Ouverte' est un cycle. Groupes: transitions uniquement."
                )
            
            # V√©rifier les donn√©es avant d'appeler la fonction
            with st.expander("üîç Debug - Analyse d√©taill√©e des donn√©es de porte", expanded=False):
                st.write("### Donn√©es brutes")
                st.write(f"- Shape: {porte_data_raw.shape}")
                st.write(f"- Colonnes: {porte_data_raw.columns.tolist()}")
                
                # Analyser les valeurs de Porte_Status
                st.write("\n### Analyse de Porte_Status")
                st.write(f"- Type de donn√©es: {porte_data_raw['Porte_Status'].dtype}")
                st.write(f"- Nombre total de valeurs: {len(porte_data_raw)}")
                st.write(f"- Valeurs non-NaN: {porte_data_raw['Porte_Status'].notna().sum()}")
                st.write(f"- Valeurs NaN: {porte_data_raw['Porte_Status'].isna().sum()}")
                
                # Filtrer les NaN
                porte_data_clean = porte_data_raw[porte_data_raw['Porte_Status'].notna()].copy()
                
                if len(porte_data_clean) > 0:
                    st.write(f"\n### Apr√®s filtrage des NaN: {len(porte_data_clean)} lignes")
                    unique_vals = porte_data_clean['Porte_Status'].unique()
                    st.write(f"- Valeurs uniques: {sorted(unique_vals)}")
                    
                    # Si les valeurs sont du texte, afficher le mapping
                    if pd.api.types.is_string_dtype(porte_data_clean['Porte_Status']):
                        st.write("\n### Mapping des valeurs textuelles:")
                        st.write("- 'Ouverte' ‚Üí 1 (porte ouverte)")
                        st.write("- 'Ferm√©' ‚Üí 0 (porte ferm√©e)")
                    
                    # Distribution des valeurs
                    value_counts = porte_data_clean['Porte_Status'].value_counts().sort_index()
                    st.write("\n### Distribution des valeurs:")
                    for val, count in value_counts.items():
                        st.write(f"  - {val}: {count} ({count/len(porte_data_clean)*100:.1f}%)")
                    
                    # V√©rifier les transitions
                    porte_sorted = porte_data_clean.sort_values('Timestamp').copy()
                    porte_sorted['prev_status'] = porte_sorted['Porte_Status'].shift(1)
                    transitions = porte_sorted[porte_sorted['Porte_Status'] != porte_sorted['prev_status']]
                    
                    st.write(f"\n### Transitions d√©tect√©es: {len(transitions)}")
                    if len(transitions) > 0:
                        st.write("Premi√®res transitions:")
                        st.dataframe(transitions[['Timestamp', 'prev_status', 'Porte_Status']].head(10))
                        
                        # Calculer les dur√©es entre transitions
                        transitions['time_diff'] = transitions['Timestamp'].diff().dt.total_seconds()
                        st.write(f"\n### Dur√©es entre transitions (secondes):")
                        st.write(f"- Moyenne: {transitions['time_diff'].mean():.1f}s")
                        st.write(f"- M√©diane: {transitions['time_diff'].median():.1f}s")
                        st.write(f"- Min: {transitions['time_diff'].min():.1f}s")
                        st.write(f"- Max: {transitions['time_diff'].max():.1f}s")
                
                # Utiliser la nouvelle fonction de d√©tection
                if len(porte_data_clean) > 0:
                    # Mode √©v√©nements individuels - traiter chaque "Ouverte" comme un cycle
                    if detection_mode == "√âv√©nements individuels":
                        # Filtrer seulement les √©v√©nements d'ouverture
                        if pd.api.types.is_string_dtype(porte_data_clean['Porte_Status']):
                            open_events_df = porte_data_clean[
                                porte_data_clean['Porte_Status'].str.lower().isin(['ouverte', 'ouvert'])
                            ].copy()
                        else:
                            # Donn√©es num√©riques (1 = ouvert, 0 = ferm√©)
                            open_events_df = porte_data_clean[
                                porte_data_clean['Porte_Status'] == 1
                            ].copy()
                        
                        cycles_list = []
                        for i, row in open_events_df.iterrows():
                            # Assumer une dur√©e fixe ou jusqu'au prochain √©v√©nement
                            open_time = row['Timestamp']
                            # Chercher le prochain √©v√©nement pour d√©terminer la dur√©e
                            next_events = porte_data_clean[porte_data_clean['Timestamp'] > open_time].head(5)
                            
                            if len(next_events) > 0:
                                # Utiliser le prochain timestamp comme fermeture approximative
                                close_time = next_events.iloc[0]['Timestamp']
                                duration = (close_time - open_time).total_seconds()
                                
                                # Si la dur√©e est trop longue, limiter √† 1 heure
                                if duration > 3600:
                                    close_time = open_time + pd.Timedelta(hours=1)
                                    duration = 3600
                            else:
                                # Pas d'√©v√©nement suivant, assumer 30 minutes
                                close_time = open_time + pd.Timedelta(minutes=30)
                                duration = 1800
                            
                            if duration >= min_duration:
                                cycles_list.append({
                                    'open_ts': open_time,
                                    'close_ts': close_time,
                                    'duration_sec': duration
                                })
                        
                        cycles_df = pd.DataFrame(cycles_list)
                        if len(cycles_df) > 0:
                            cycles_df = cycles_df.sort_values('open_ts').reset_index(drop=True)
                        else:
                            cycles_df = pd.DataFrame(columns=['open_ts', 'close_ts', 'duration_sec'])
                            
                        st.info(f"Mode √©v√©nements individuels: {len(open_events_df)} √©v√©nements 'Ouverte' d√©tect√©s ‚Üí {len(cycles_df)} cycles cr√©√©s")
                    else:
                        # Mode normal ou automatique
                        cycles_df = detect_door_cycles(
                            porte_data_clean,
                            ts_col='Timestamp', 
                            status_col='Porte_Status',
                            min_duration_sec=min_duration,
                            max_duration_hours=max_duration
                        )
                    
                    st.write(f"\n### R√©sultat de la d√©tection: {len(cycles_df)} cycles")
                    if len(cycles_df) > 0:
                        st.write("Cycles d√©tect√©s:")
                        cycles_display = cycles_df.copy()
                        cycles_display['duration_min'] = cycles_display['duration_sec'] / 60
                        st.dataframe(cycles_display)
                else:
                    st.warning("Aucune donn√©e de porte valide trouv√©e")
                    cycles_df = pd.DataFrame()
            
            # Debug: Afficher les cycles d√©tect√©s
            with st.expander("üîç Debug - Cycles d√©tect√©s"):
                st.write(f"Nombre de cycles trouv√©s: {len(cycles_df)}")
                
                # Afficher les donn√©es brutes pour debug
                if hasattr(cycles_df, 'attrs') and 'debug_df' in cycles_df.attrs:
                    st.write("\n### √âchantillon des donn√©es brutes:")
                    debug_df = cycles_df.attrs['debug_df']
                    # Ajouter une colonne pour mieux voir les √©tats
                    debug_df_display = debug_df.copy()
                    debug_df_display['√âtat'] = debug_df_display['state'].map({0: 'üî¥ Ferm√©', 1: 'üü¢ Ouvert'})
                    st.dataframe(debug_df_display[['Timestamp', 'Porte_Status', '√âtat']].head(50))
                
                if len(cycles_df) > 0:
                    st.write("\n### Cycles d√©tect√©s:")
                    display_df = cycles_df.copy()
                    display_df['duration_min'] = display_df['duration_sec'] / 60
                    display_df['open_time'] = display_df['open_ts'].dt.strftime('%Y-%m-%d %H:%M:%S')
                    display_df['close_time'] = display_df['close_ts'].dt.strftime('%Y-%m-%d %H:%M:%S')
                    
                    # Afficher tous les cycles si moins de 50, sinon les 50 premiers
                    n_display = len(display_df) if len(display_df) < 50 else 50
                    st.dataframe(display_df[['open_time', 'close_time', 'duration_min']].head(n_display))
                    
                    # Statistiques
                    st.write("\n### Statistiques des cycles:")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Dur√©e moyenne", f"{display_df['duration_min'].mean():.1f} min")
                    with col2:
                        st.metric("Dur√©e m√©diane", f"{display_df['duration_min'].median():.1f} min")
                    with col3:
                        st.metric("Total cycles", len(display_df))
                    
                    # Distribution des dur√©es
                    st.write("\n### Distribution des dur√©es:")
                    st.write(f"- < 1 min: {len(display_df[display_df['duration_min'] < 1])} cycles")
                    st.write(f"- 1-10 min: {len(display_df[(display_df['duration_min'] >= 1) & (display_df['duration_min'] < 10)])} cycles")
                    st.write(f"- 10-60 min: {len(display_df[(display_df['duration_min'] >= 10) & (display_df['duration_min'] < 60)])} cycles")
                    st.write(f"- > 60 min: {len(display_df[display_df['duration_min'] >= 60])} cycles")
            
            # Visualisation de l'√©tat de la porte dans le temps
            if len(porte_data_clean) > 0:
                st.subheader("üìä √âtat de la porte dans le temps")
                
                # Cr√©er une figure pour l'√©tat de la porte
                fig_status = go.Figure()
                
                # Pr√©parer les donn√©es pour la visualisation
                plot_data = porte_data_clean.copy()
                plot_data = plot_data.sort_values('Timestamp')
                
                # Convertir le statut en num√©rique si n√©cessaire
                if pd.api.types.is_string_dtype(plot_data['Porte_Status']):
                    status_map = {'ouverte': 1, 'ouvert': 1, 'ferm√©': 0, 'ferme': 0, 'ferm√©e': 0}
                    plot_data['Status_Numeric'] = plot_data['Porte_Status'].str.lower().map(status_map).fillna(0)
                else:
                    plot_data['Status_Numeric'] = pd.to_numeric(plot_data['Porte_Status'], errors='coerce').fillna(0)
                
                # Ajouter la ligne d'√©tat
                fig_status.add_trace(go.Scatter(
                    x=plot_data['Timestamp'],
                    y=plot_data['Status_Numeric'],
                    mode='lines',
                    line=dict(shape='hv', color='blue', width=2),
                    fill='tozeroy',
                    fillcolor='rgba(0, 100, 255, 0.3)',
                    name='√âtat porte',
                    hovertemplate='%{x}<br>√âtat: %{y}<extra></extra>'
                ))
                
                # Ajouter des zones color√©es pour les cycles d√©tect√©s
                for i, row in cycles_df.iterrows():
                    fig_status.add_vrect(
                        x0=row['open_ts'], x1=row['close_ts'],
                        fillcolor="red", opacity=0.2,
                        layer="below", line_width=0,
                        annotation_text=f"C{i+1}",
                        annotation_position="top left"
                    )
                
                fig_status.update_layout(
                    title="√âtat de la porte et cycles d√©tect√©s",
                    xaxis_title="Temps",
                    yaxis_title="√âtat (0=Ferm√©, 1=Ouvert)",
                    height=400,
                    yaxis=dict(
                        tickmode='array',
                        tickvals=[0, 1],
                        ticktext=['Ferm√©', 'Ouvert'],
                        range=[-0.1, 1.1]
                    ),
                    showlegend=False
                )
                
                st.plotly_chart(fig_status, use_container_width=True)
            
            # Visualisation Timeline des cycles de porte
            if len(cycles_df) > 0:
                st.subheader("üìÖ Timeline des cycles de porte")
                
                # Cr√©er une figure pour la timeline
                fig_timeline = go.Figure()
                
                # Ajouter chaque cycle comme une barre horizontale
                for i, row in cycles_df.iterrows():
                    fig_timeline.add_trace(go.Scatter(
                        x=[row['open_ts'], row['close_ts']],
                        y=[i, i],
                        mode='lines',
                        line=dict(color='red', width=10),
                        name=f"Cycle {i+1}",
                        hovertemplate=(
                            f"Cycle {i+1}<br>" +
                            "Ouverture: %{x|%Y-%m-%d %H:%M:%S}<br>" +
                            f"Dur√©e: {row['duration_sec']/60:.1f} min<extra></extra>"
                        ),
                        showlegend=False
                    ))
                    
                    # Ajouter des marqueurs pour d√©but et fin
                    fig_timeline.add_trace(go.Scatter(
                        x=[row['open_ts'], row['close_ts']],
                        y=[i, i],
                        mode='markers',
                        marker=dict(size=12, color=['green', 'red']),
                        showlegend=False,
                        hoverinfo='skip'
                    ))
                
                # Mise en forme de la timeline
                fig_timeline.update_layout(
                    title="Chronologie des ouvertures de porte",
                    xaxis_title="Temps",
                    yaxis_title="Cycles",
                    height=max(300, min(600, 50 + len(cycles_df) * 30)),
                    yaxis=dict(
                        tickmode='linear',
                        tick0=0,
                        dtick=1,
                        ticktext=[f"Cycle {i+1}" for i in range(len(cycles_df))],
                        tickvals=list(range(len(cycles_df)))
                    ),
                    showlegend=False,
                    hovermode='closest'
                )
                
                # Ajouter une annotation pour la l√©gende
                fig_timeline.add_annotation(
                    text="üü¢ Ouverture | üî¥ Fermeture",
                    xref="paper", yref="paper",
                    x=0.5, y=1.05,
                    showarrow=False,
                    font=dict(size=12)
                )
                
                st.plotly_chart(fig_timeline, use_container_width=True)
                
                # Statistiques rapides
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Total cycles", len(cycles_df))
                with col2:
                    st.metric("Dur√©e moyenne", f"{cycles_df['duration_sec'].mean()/60:.1f} min")
                with col3:
                    st.metric("Dur√©e totale", f"{cycles_df['duration_sec'].sum()/60:.1f} min")
                with col4:
                    if len(filtered_merged_data) > 0:
                        time_range = (filtered_merged_data['Timestamp'].max() - filtered_merged_data['Timestamp'].min()).total_seconds() / 3600
                        if time_range > 0:
                            freq = len(cycles_df) / time_range
                            st.metric("Fr√©quence", f"{freq:.2f} cycles/h")
            
            # Convertir en format attendu par le reste du code
            open_events = cycles_df['open_ts'].tolist()
            close_events = cycles_df['close_ts'].tolist()
            
            st.write(f"**Cycles valides d√©tect√©s:** {len(cycles_df)} cycles")
            
            # Analyse des cycles ouverture-fermeture
            st.subheader("üìà Analyse de l'√©volution de temp√©rature pendant l'ouverture de porte")
            
            # Utiliser les √©v√©nements d'ouverture d√©tect√©s pour cr√©er des cycles
            door_cycles = []
            all_door_cycles = []  # Nouveau: garder tous les cycles m√™me sans temp√©rature
            
            if len(cycles_df) > 0:
                st.write(f"**Traitement de {len(cycles_df)} cycles d√©tect√©s...**")
                
                # NOUVELLE APPROCHE: Pr√©traiter les donn√©es de temp√©rature
                # 1. Cr√©er une copie pour le traitement
                temp_processed = filtered_merged_data[['Timestamp', 'Temp_Ambiante']].copy()
                temp_processed = temp_processed.sort_values('Timestamp')
                
                # 2. Statistiques avant traitement
                nan_before = temp_processed['Temp_Ambiante'].isna().sum()
                total_rows = len(temp_processed)
                st.write(f"**Donn√©es temp√©rature - Avant traitement:** {total_rows - nan_before}/{total_rows} valeurs valides ({nan_before} NaN)")
                
                # 3. Remplir les NaN intelligemment
                # D'abord, interpolation lin√©aire pour les petits gaps
                temp_processed['Temp_Ambiante_Interpolated'] = temp_processed['Temp_Ambiante'].interpolate(
                    method='linear', 
                    limit=10  # Max 10 points cons√©cutifs
                )
                
                # Ensuite, forward fill puis backward fill pour les gaps restants
                temp_processed['Temp_Ambiante_Filled'] = temp_processed['Temp_Ambiante_Interpolated'].ffill().bfill()
                
                # Si encore des NaN (d√©but/fin), utiliser la moyenne globale
                global_mean = temp_processed['Temp_Ambiante'].mean()
                if pd.notna(global_mean):
                    temp_processed['Temp_Ambiante_Final'] = temp_processed['Temp_Ambiante_Filled'].fillna(global_mean)
                else:
                    temp_processed['Temp_Ambiante_Final'] = temp_processed['Temp_Ambiante_Filled']
                
                # 4. Statistiques apr√®s traitement
                nan_after = temp_processed['Temp_Ambiante_Final'].isna().sum()
                st.write(f"**Donn√©es temp√©rature - Apr√®s traitement:** {total_rows - nan_after}/{total_rows} valeurs valides")
                
                # 5. Remplacer dans filtered_merged_data
                filtered_merged_data['Temp_Ambiante_Original'] = filtered_merged_data['Temp_Ambiante'].copy()
                filtered_merged_data = filtered_merged_data.merge(
                    temp_processed[['Timestamp', 'Temp_Ambiante_Final']], 
                    on='Timestamp', 
                    how='left'
                )
                filtered_merged_data['Temp_Ambiante'] = filtered_merged_data['Temp_Ambiante_Final']
                
                # Debug: Variables pour suivre le traitement
                cycles_with_no_temp_data = 0
                cycles_with_invalid_temps = 0
                
                # Pour chaque cycle, analyser l'impact sur la temp√©rature
                for i, cycle in cycles_df.iterrows():
                    open_time = cycle['open_ts']
                    close_time = cycle['close_ts']
                    cycle_duration = cycle['duration_sec'] / 60  # Convertir en minutes
                    
                    # Limiter les cycles tr√®s longs (plus de 2 heures)
                    if cycle_duration > 120:
                        close_time = open_time + timedelta(minutes=120)
                        cycle_duration = 120
                    
                    # Enregistrer tous les cycles (avec ou sans temp√©rature)
                    all_door_cycles.append({
                        'Open_Time': open_time,
                        'Close_Time': close_time,
                        'Duration_min': cycle_duration,
                        'Is_Complete_Cycle': True,  # Tous les cycles d√©tect√©s sont complets
                        'Has_Temp_Data': False  # Sera mis √† jour plus tard
                    })
                    
                    # NOUVELLE LOGIQUE: Plus flexible pour trouver les temp√©ratures
                    
                    # 1. Temp√©rature AVANT l'ouverture (baseline)
                    # Chercher dans les 30 minutes avant, mais prendre les 5 derni√®res minutes de pr√©f√©rence
                    before_window_start = open_time - timedelta(minutes=30)
                    before_window_end = open_time
                    
                    before_data = filtered_merged_data[
                        (filtered_merged_data['Timestamp'] >= before_window_start) & 
                        (filtered_merged_data['Timestamp'] < before_window_end)
                    ].copy()
                    
                    # Prendre la moyenne des 5 derni√®res minutes si possible
                    before_5min = before_data[before_data['Timestamp'] >= (open_time - timedelta(minutes=5))]
                    if len(before_5min) > 0:
                        temp_before = before_5min['Temp_Ambiante'].mean()
                    elif len(before_data) > 0:
                        # Sinon, prendre la derni√®re valeur disponible
                        temp_before = before_data.iloc[-1]['Temp_Ambiante']
                    else:
                        temp_before = np.nan
                    
                    # 2. Temp√©rature PENDANT/APR√àS le cycle
                    # Chercher pendant tout le cycle + 10 minutes apr√®s
                    after_window_start = open_time
                    after_window_end = close_time + timedelta(minutes=10)
                    
                    after_data = filtered_merged_data[
                        (filtered_merged_data['Timestamp'] >= after_window_start) & 
                        (filtered_merged_data['Timestamp'] <= after_window_end)
                    ].copy()
                    
                    # Prendre le maximum pendant le cycle (pire cas)
                    if len(after_data) > 0:
                        temp_after = after_data['Temp_Ambiante'].max()
                    else:
                        temp_after = np.nan
                    
                    # 3. Donn√©es compl√®tes pour visualisation
                    full_window_start = before_window_start
                    full_window_end = after_window_end
                    
                    full_cycle_data = filtered_merged_data[
                        (filtered_merged_data['Timestamp'] >= full_window_start) & 
                        (filtered_merged_data['Timestamp'] <= full_window_end)
                    ].copy()
                    
                    # Debug: Afficher les infos de matching temp√©rature pour les premiers cycles
                    if i < 3:  # Debug pour les 3 premiers cycles
                        with st.expander(f"üîç Debug temp√©rature cycle {i+1}"):
                            st.write(f"Ouverture: {open_time}, Fermeture: {close_time}")
                            st.write(f"Fen√™tre avant: {before_window_start} √† {before_window_end}")
                            st.write(f"Points de donn√©es avant: {len(before_data)}")
                            st.write(f"Temp avant: {temp_before:.2f}¬∞C" if pd.notna(temp_before) else "Temp avant: NaN")
                            st.write(f"Fen√™tre apr√®s: {after_window_start} √† {after_window_end}")
                            st.write(f"Points de donn√©es apr√®s: {len(after_data)}")
                            st.write(f"Temp apr√®s (max): {temp_after:.2f}¬∞C" if pd.notna(temp_after) else "Temp apr√®s: NaN")
                        
                    # V√©rifier que les temp√©ratures sont valides
                    if pd.notna(temp_before) and pd.notna(temp_after):
                        # Marquer ce cycle comme ayant des donn√©es de temp√©rature
                        all_door_cycles[-1]['Has_Temp_Data'] = True
                        
                        door_cycles.append({
                            'Open_Time': open_time,
                            'Close_Time': close_time,
                            'Duration_min': cycle_duration,
                            'Temp_Before': temp_before,
                            'Temp_After': temp_after,
                            'Delta_Temp': temp_after - temp_before,
                            'Cycle_Data': full_cycle_data,
                            'Before_Data': before_data,
                            'After_Data': after_data,
                            'Is_Complete_Cycle': True
                        })
                    else:
                        if pd.isna(temp_before) or pd.isna(temp_after):
                            cycles_with_invalid_temps += 1
                        else:
                            cycles_with_no_temp_data += 1
                            
                st.write(f"**Total de cycles d√©tect√©s:** {len(all_door_cycles)}")
                st.write(f"**Cycles avec donn√©es de temp√©rature:** {len(door_cycles)}")
                
                # Debug: Afficher pourquoi des cycles ont √©t√© filtr√©s
                with st.expander("üîç Debug - R√©sum√© du traitement des cycles"):
                    st.write("**Nouvelle approche de traitement:**")
                    st.write("1. ‚úÖ Interpolation des NaN dans les donn√©es de temp√©rature")
                    st.write("2. ‚úÖ Fen√™tres de temps flexibles (30 min avant, cycle + 10 min apr√®s)")
                    st.write("3. ‚úÖ Temp√©rature avant = moyenne des 5 derni√®res minutes")
                    st.write("4. ‚úÖ Temp√©rature apr√®s = maximum pendant le cycle")
                    st.write("")
                    st.write(f"Total cycles d√©tect√©s (apr√®s filtrage): {len(cycles_df)}")
                    st.write(f"Total cycles cr√©√©s: {len(all_door_cycles)}")
                    st.write(f"Cycles sans donn√©es de temp√©rature: {cycles_with_no_temp_data}")
                    st.write(f"Cycles avec temp√©ratures invalides: {cycles_with_invalid_temps}")
                    st.write(f"**Cycles avec donn√©es de temp√©rature compl√®tes: {len(door_cycles)}**")
                    
                # Afficher tous les cycles dans un tableau
                with st.expander("üìä Voir tous les cycles d√©tect√©s"):
                    if all_door_cycles:
                        df_all_cycles = pd.DataFrame(all_door_cycles)
                        df_all_cycles['Open_Time'] = pd.to_datetime(df_all_cycles['Open_Time'])
                        df_all_cycles['Close_Time'] = pd.to_datetime(df_all_cycles['Close_Time'])
                        
                        # Ajouter des colonnes format√©es pour l'affichage
                        df_all_cycles['Ouverture'] = df_all_cycles['Open_Time'].dt.strftime('%d/%m/%Y %H:%M')
                        df_all_cycles['Fermeture'] = df_all_cycles['Close_Time'].dt.strftime('%d/%m/%Y %H:%M')
                        df_all_cycles['Dur√©e (min)'] = df_all_cycles['Duration_min'].round(1)
                        df_all_cycles['Cycle complet'] = df_all_cycles['Is_Complete_Cycle'].map({True: '‚úì', False: '‚úó'})
                        df_all_cycles['Donn√©es temp.'] = df_all_cycles['Has_Temp_Data'].map({True: '‚úì', False: '‚úó'})
                        
                        # Afficher le tableau
                        st.dataframe(
                            df_all_cycles[['Ouverture', 'Fermeture', 'Dur√©e (min)', 'Cycle complet', 'Donn√©es temp.']],
                            use_container_width=True
                        )
                        
                        # Statistiques suppl√©mentaires
                        st.write(f"**Statistiques des cycles:**")
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Dur√©e moyenne", f"{df_all_cycles['Duration_min'].mean():.1f} min")
                        with col2:
                            cycles_with_temp = df_all_cycles['Has_Temp_Data'].sum()
                            pct_with_temp = (cycles_with_temp / len(df_all_cycles)) * 100
                            st.metric("% avec donn√©es temp.", f"{pct_with_temp:.1f}%")
                        with col3:
                            complete_cycles = df_all_cycles['Is_Complete_Cycle'].sum()
                            st.metric("Cycles complets", f"{complete_cycles}/{len(df_all_cycles)}")
            
            if len(door_cycles) > 0:
                # Convertir en DataFrame pour les statistiques
                door_impacts = []
                for cycle in door_cycles:
                    # V√©rifier que les valeurs ne sont pas NaN
                    if (pd.notna(cycle['Temp_Before']) and 
                        pd.notna(cycle['Temp_After']) and 
                        pd.notna(cycle['Duration_min'])):
                        
                        door_impacts.append({
                            'Timestamp': cycle['Open_Time'],
                            'Duree_Analyse': cycle['Duration_min'],
                            'Temp_Avant': cycle['Temp_Before'],
                            'Temp_Apres': cycle['Temp_After'],
                            'Delta_Temp': cycle['Delta_Temp']
                        })
                
                st.write(f"**Cycles valides apr√®s nettoyage:** {len(door_impacts)}")
                
                if door_impacts and len(door_impacts) > 0:
                    df_impacts = pd.DataFrame(door_impacts)
                    
                    # Debug temporaire: Afficher les donn√©es pour v√©rifier
                    with st.expander("üîç D√©bogage - Voir les donn√©es"):
                        st.write(f"Shape df_impacts: {df_impacts.shape}")
                        st.write("Colonnes:", df_impacts.columns.tolist())
                        st.write("Premi√®res lignes:")
                        st.dataframe(df_impacts.head())
                        st.write("Valeurs NaN par colonne:")
                        st.write(df_impacts.isnull().sum())
                    
                    # Graphiques d'analyse
                    
                    # 1. S√©lection individuelle de cycle avec dropdown
                    st.subheader("üìà √âvolution temporelle de la temp√©rature par cycle")
                    
                    # Cr√©er le dropdown pour s√©lectionner un cycle sp√©cifique
                    cycle_idx = st.selectbox(
                        "S√©lectionner un cycle √† visualiser",
                        range(len(door_cycles)),
                        format_func=lambda x: f"Cycle {x+1} - {door_cycles[x]['Open_Time'].strftime('%Y-%m-%d %H:%M')} (ŒîT: {door_cycles[x]['Delta_Temp']:.2f}¬∞C, Dur√©e: {door_cycles[x]['Duration_min']:.1f} min)"
                    )
                    
                    if cycle_idx is not None:
                        selected_cycle = door_cycles[cycle_idx]
                        
                        # Visualisation d√©taill√©e du cycle s√©lectionn√©
                        cycle_data = selected_cycle['Cycle_Data']
                        if len(cycle_data) > 0:
                            fig_selected = go.Figure()
                            
                            # Temp√©rature
                            fig_selected.add_trace(go.Scatter(
                                x=cycle_data['Timestamp'],
                                y=cycle_data['Temp_Ambiante'],
                                mode='lines+markers',
                                name='Temp√©rature',
                                line=dict(color='red', width=2),
                                marker=dict(size=6)
                            ))
                            
                            # Marquer l'ouverture de porte
                            fig_selected.add_shape(
                                type="line",
                                x0=selected_cycle['Open_Time'], x1=selected_cycle['Open_Time'],
                                y0=0, y1=1,
                                yref="paper",
                                line=dict(color="green", width=2, dash="dash")
                            )
                            fig_selected.add_annotation(
                                x=selected_cycle['Open_Time'],
                                y=1.05,
                                yref="paper",
                                text="Ouverture",
                                showarrow=False
                            )
                            
                            # Marquer la fermeture de porte
                            fig_selected.add_shape(
                                type="line",
                                x0=selected_cycle['Close_Time'], x1=selected_cycle['Close_Time'],
                                y0=0, y1=1,
                                yref="paper",
                                line=dict(color="orange", width=2, dash="dash")
                            )
                            fig_selected.add_annotation(
                                x=selected_cycle['Close_Time'],
                                y=1.05,
                                yref="paper",
                                text="Fermeture",
                                showarrow=False
                            )
                            
                            # Ajouter les lignes horizontales pour les temp√©ratures avant/apr√®s
                            fig_selected.add_hline(
                                y=selected_cycle['Temp_Before'],
                                line_dash="dot",
                                line_color="blue",
                                annotation_text=f"Temp avant: {selected_cycle['Temp_Before']:.1f}¬∞C"
                            )
                            
                            fig_selected.add_hline(
                                y=selected_cycle['Temp_After'],
                                line_dash="dot",
                                line_color="purple",
                                annotation_text=f"Temp apr√®s: {selected_cycle['Temp_After']:.1f}¬∞C"
                            )
                            
                            fig_selected.update_layout(
                                title=f"Cycle {cycle_idx+1} - {selected_cycle['Open_Time'].strftime('%Y-%m-%d %H:%M')} (Dur√©e: {selected_cycle['Duration_min']:.1f} min, ŒîT: {selected_cycle['Delta_Temp']:.2f}¬∞C)",
                                xaxis_title="Temps",
                                yaxis_title="Temp√©rature (¬∞C)",
                                height=450,
                                hovermode='x unified'
                            )
                            
                            st.plotly_chart(fig_selected, use_container_width=True)
                            
                            # Afficher les d√©tails du cycle s√©lectionn√©
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Temp√©rature avant", f"{selected_cycle['Temp_Before']:.1f}¬∞C")
                            with col2:
                                st.metric("Temp√©rature apr√®s", f"{selected_cycle['Temp_After']:.1f}¬∞C")
                            with col3:
                                st.metric("Variation", f"{selected_cycle['Delta_Temp']:.2f}¬∞C",
                                        delta=f"{'‚Üë' if selected_cycle['Delta_Temp'] > 0 else '‚Üì'} {abs(selected_cycle['Delta_Temp']):.2f}¬∞C")
                            with col4:
                                st.metric("Dur√©e", f"{selected_cycle['Duration_min']:.1f} min")
                    
                    # 2. Graphique comparatif: Vue d'ensemble de tous les cycles
                    st.subheader("üìä Comparaison de tous les cycles")
                    
                    fig = go.Figure()
                    
                    # Ajouter chaque cycle comme une s√©rie
                    colors = px.colors.qualitative.Set3
                    for i, cycle in enumerate(door_cycles[:10]):  # Limiter √† 10 cycles pour la lisibilit√©
                        cycle_data = cycle['Cycle_Data']
                        if len(cycle_data) > 0:
                            # Calculer le temps relatif depuis l'ouverture (en minutes)
                            relative_time = [(t - cycle['Open_Time']).total_seconds() / 60 
                                           for t in cycle_data['Timestamp']]
                            
                            fig.add_trace(go.Scatter(
                                x=relative_time,
                                y=cycle_data['Temp_Ambiante'],
                                mode='lines+markers',
                                name=f"Cycle {i+1} ({cycle['Open_Time'].strftime('%m-%d %H:%M')})",
                                line=dict(color=colors[i % len(colors)], width=2),
                                marker=dict(size=6),
                                hovertemplate='Temps: %{x:.1f} min<br>Temp: %{y:.1f}¬∞C<extra></extra>'
                            ))
                            
                            # Ajouter une ligne verticale pour marquer l'ouverture de porte
                            fig.add_vline(
                                x=0, 
                                line_dash="dash", 
                                line_color="red",
                                opacity=0.7,
                                annotation_text=f"Ouverture {i+1}",
                                annotation_position="top"
                            )
                    
                    fig.update_layout(
                        title="√âvolution de temp√©rature pendant les cycles d'ouverture",
                        xaxis_title="Temps depuis ouverture (minutes)",
                        yaxis_title="Temp√©rature ambiante (¬∞C)",
                        height=500,
                        hovermode='x unified'
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # 2. Graphique de corr√©lation dur√©e vs changement temp√©rature
                    st.subheader("üìä Analyse de corr√©lation")
                    
                    # Utiliser une seule colonne au lieu de deux
                    with st.container():
                        # Corr√©lation dur√©e vs changement temp√©rature
                        fig = go.Figure()
                        
                        fig.add_trace(go.Scatter(
                            x=df_impacts['Duree_Analyse'],
                            y=df_impacts['Delta_Temp'],
                            mode='markers',
                            marker=dict(size=10, color='darkblue', opacity=0.7),
                            name='Cycles',
                            text=[f"Cycle {i+1}<br>Dur√©e: {d:.1f} min<br>ŒîT: {t:.2f}¬∞C" 
                                  for i, (d, t) in enumerate(zip(df_impacts['Duree_Analyse'], df_impacts['Delta_Temp']))],
                            hovertemplate='%{text}<extra></extra>'
                        ))
                        
                        # Ligne de tendance si assez de points
                        # Commented out because duration is constant
                        # if len(df_impacts) > 3:
                        #     z = np.polyfit(df_impacts['Duree_Analyse'], df_impacts['Delta_Temp'], 1)
                        #     p = np.poly1d(z)
                        #     x_trend = np.linspace(df_impacts['Duree_Analyse'].min(), 
                        #                         df_impacts['Duree_Analyse'].max(), 100)
                        #     fig.add_trace(go.Scatter(
                        #         x=x_trend,
                        #         y=p(x_trend),
                        #         mode='lines',
                        #         line=dict(color='red', dash='dash'),
                        #         name='Tendance'
                        #     ))
                        
                        fig.add_hline(y=0, line_dash="dash", line_color="gray")
                        
                        fig.update_layout(
                            title="Dur√©e vs Changement temp√©rature",
                            xaxis_title="Dur√©e d'ouverture (min)",
                            yaxis_title="ŒîT (¬∞C)",
                            height=400
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Statistiques des cycles
                    st.subheader("üìä Statistiques des cycles d'ouverture")
                    
                    # Utiliser les donn√©es valides seulement
                    valid_data = df_impacts.dropna(subset=['Delta_Temp', 'Duree_Analyse'])
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Nombre de cycles", len(valid_data))
                    with col2:
                        if len(valid_data) > 0:
                            st.metric("ŒîT moyen", f"{valid_data['Delta_Temp'].mean():.2f}¬∞C")
                        else:
                            st.metric("ŒîT moyen", "N/A")
                    with col3:
                        if len(valid_data) > 0:
                            avg_duration = valid_data['Duree_Analyse'].mean()
                            st.metric("Dur√©e moyenne cycle", f"{avg_duration:.0f} min")
                        else:
                            st.metric("Dur√©e moyenne cycle", "N/A")
                    with col4:
                        if len(valid_data) > 0:
                            st.metric("ŒîT max", f"{valid_data['Delta_Temp'].max():.2f}¬∞C")
                        else:
                            st.metric("ŒîT max", "N/A")
                    
                    # Tableau d√©taill√©
                    with st.expander("üìã D√©tail des cycles d'ouverture-fermeture"):
                        st.dataframe(
                            df_impacts.style.format({
                                'Duree_Analyse': '{:.0f} min',
                                'Temp_Avant': '{:.1f}¬∞C',
                                'Temp_Apres': '{:.1f}¬∞C',
                                'Delta_Temp': '{:.2f}¬∞C'
                            }),
                            use_container_width=True
                        )
                    
                    # Interpr√©tation
                    if len(valid_data) > 0:
                        avg_impact = valid_data['Delta_Temp'].mean()
                        avg_duration = valid_data['Duree_Analyse'].mean()  # Dur√©e moyenne des cycles
                        
                        if avg_impact > 0.1:
                            interpretation = f"üî• Pendant l'ouverture de porte (dur√©e moyenne: {avg_duration:.1f} min), la temp√©rature tend √† **augmenter** de {avg_impact:.2f}¬∞C en moyenne."
                        elif avg_impact < -0.1:
                            interpretation = f"‚ùÑÔ∏è Pendant l'ouverture de porte (dur√©e moyenne: {avg_duration:.1f} min), la temp√©rature tend √† **diminuer** de {abs(avg_impact):.2f}¬∞C en moyenne."
                        else:
                            interpretation = f"üå°Ô∏è Pendant l'ouverture de porte (dur√©e moyenne: {avg_duration:.1f} min), la temp√©rature reste **relativement stable**."
                    else:
                        interpretation = "‚ö†Ô∏è Pas assez de donn√©es valides pour faire une interpr√©tation."
                    
                    st.info(interpretation)
                    
                else:
                    st.warning("Impossible de calculer l'impact sur la temp√©rature - donn√©es insuffisantes.")
            else:
                st.warning("Aucun cycle d'ouverture valide trouv√©. V√©rifiez que les donn√©es de temp√©rature sont disponibles pendant les p√©riodes d'ouverture.")
                
                # Si on a d√©tect√© des cycles mais aucun avec temp√©rature
                if len(all_door_cycles) > 0:
                    st.info(f"‚ÑπÔ∏è Cependant, {len(all_door_cycles)} cycles de porte ont √©t√© d√©tect√©s. Consultez l'onglet 'Voir tous les cycles d√©tect√©s' ci-dessus pour plus de d√©tails.")
        else:
            st.warning("Aucun √©v√©nement d'ouverture de porte d√©tect√© dans les donn√©es.")
    else:
        st.warning("Donn√©es de porte ou de temp√©rature manquantes pour l'analyse.")

# 6. ANALYSE PORTE
with tab6:
    st.info(f"üìÖ P√©riode s√©lectionn√©e: {start_date.strftime('%Y-%m-%d %H:%M')} - {end_date.strftime('%Y-%m-%d %H:%M')}")
    if render_incident_lens_interface:
        # Pass filtered data to Incident Lens
        render_incident_lens_interface(data=filtered_merged_data, start_date=start_date, end_date=end_date)
    else:
        st.error("üö´ Incident Lens non disponible - probl√®me d'import des modules")
        st.info("üìã V√©rifiez que tous les modules sont correctement install√©s")

# 7. CORR√âLATIONS
with tab7:
    st.header("üîó Analyse des Relations entre Variables")
    st.info(f"üìÖ P√©riode s√©lectionn√©e: {start_date.strftime('%Y-%m-%d %H:%M')} - {end_date.strftime('%Y-%m-%d %H:%M')}")
    
    # S√©lection des variables pour la corr√©lation
    numeric_vars = ['Temp_Ambiante', 'Temp_Exterieure', 'Puissance_IT', 'Porte_Status']
    
    # Ajouter les colonnes CLIM individuelles si elles existent
    clim_status_columns = [col for col in filtered_merged_data.columns if 'CLIM' in col and 'Status' in col]
    numeric_vars.extend(clim_status_columns)
    
    available_vars = [var for var in numeric_vars if var in filtered_merged_data.columns]
    
    if len(available_vars) >= 2:
        # Create a copy for correlation calculation to avoid modifying original data
        corr_data = filtered_merged_data[available_vars].copy()
        
        
        # Convert Porte_Status to numeric if needed
        if 'Porte_Status' in corr_data.columns:
            if corr_data['Porte_Status'].dtype == 'object':
                corr_data['Porte_Status'] = corr_data['Porte_Status'].map({
                    'Open': 1, 'Ouvert': 1, 'open': 1, '1': 1, 1: 1,
                    'Close': 0, 'Ferm√©': 0, 'closed': 0, '0': 0, 0: 0
                })
            corr_data['Porte_Status'] = pd.to_numeric(corr_data['Porte_Status'], errors='coerce')
        
        # Convert CLIM columns to numeric
        for col in clim_status_columns:
            if col in corr_data.columns:
                if corr_data[col].dtype == 'object':
                    corr_data[col] = corr_data[col].map({
                        'ON': 1, 'on': 1, 'On': 1, '1': 1, 1: 1,
                        'OFF': 0, 'off': 0, 'Off': 0, '0': 0, 0: 0
                    })
                corr_data[col] = pd.to_numeric(corr_data[col], errors='coerce')
        
        # Only keep rows where at least 50% of values are non-NaN
        min_non_nan = len(available_vars) * 0.5
        corr_data = corr_data.dropna(thresh=min_non_nan)
        
        # Calculate correlation matrix with both methods
        if len(corr_data) > 10:  # Need minimum data points
            # Calculate both Pearson and Spearman
            pearson_corr = corr_data.corr(method='pearson')
            spearman_corr = corr_data.corr(method='spearman')
            
            # Use Spearman by default as it's more robust
            corr_matrix = spearman_corr
        else:
            st.warning("‚ö†Ô∏è Donn√©es insuffisantes pour calculer les relations. Au moins 10 points de donn√©es sont n√©cessaires.")
            corr_matrix = pd.DataFrame()
        
        if not corr_matrix.empty and 'Temp_Ambiante' in corr_matrix.columns:
            
            # Extract correlations with Temp_Ambiante
            temp_correlations = corr_matrix['Temp_Ambiante'].drop('Temp_Ambiante', errors='ignore')
            
            # Function to interpret correlation strength
            def interpret_correlation(value):
                abs_val = abs(value)
                if abs_val >= 0.8:
                    return "tr√®s forte", "üî¥"
                elif abs_val >= 0.6:
                    return "forte", "üü†"
                elif abs_val >= 0.4:
                    return "mod√©r√©e", "üü°"
                elif abs_val >= 0.2:
                    return "faible", "üü¢"
                else:
                    return "n√©gligeable", "‚ö™"
            
            # Function to get relationship description
            def get_relationship_description(var, corr_value):
                strength, emoji = interpret_correlation(corr_value)
                
                if pd.isna(corr_value):
                    return f"{emoji} **{var}**: Donn√©es insuffisantes pour √©tablir une relation"
                
                if abs(corr_value) < 0.2:
                    return f"{emoji} **{var}**: Aucune relation significative d√©tect√©e"
                
                direction = "augmente" if corr_value > 0 else "diminue"
                opposite = "augmente" if corr_value > 0 else "diminue"
                
                # Custom descriptions for each variable
                descriptions = {
                    'Temp_Exterieure': {
                        'positive': f"Quand la temp√©rature ext√©rieure augmente, la temp√©rature ambiante tend √† augmenter √©galement (relation {strength})",
                        'negative': f"Quand la temp√©rature ext√©rieure augmente, la temp√©rature ambiante tend √† diminuer (relation {strength} - situation inhabituelle)"
                    },
                    'Puissance_IT': {
                        'positive': f"Quand la charge IT augmente, la temp√©rature ambiante augmente (relation {strength})",
                        'negative': f"Quand la charge IT augmente, la temp√©rature ambiante diminue (relation {strength} - situation inhabituelle)"
                    },
                    'Porte_Status': {
                        'positive': f"Les ouvertures de porte ont tendance √† faire augmenter la temp√©rature ambiante (relation {strength})",
                        'negative': f"Les ouvertures de porte ont tendance √† faire baisser la temp√©rature ambiante (relation {strength})"
                    }
                }
                
                # For CLIM units
                if 'CLIM' in var and 'Status' in var:
                    if corr_value < 0:
                        return f"L'activation de {var.replace('_Status', '')} aide √† r√©duire la temp√©rature (relation {strength})"
                    else:
                        return f"L'activation de {var.replace('_Status', '')} est associ√©e √† une hausse de temp√©rature (relation {strength} - v√©rifier l'efficacit√©)"
                
                # Get appropriate description
                if var in descriptions:
                    desc_key = 'positive' if corr_value > 0 else 'negative'
                    base_desc = descriptions[var][desc_key]
                else:
                    base_desc = f"Relation {strength} {'positive' if corr_value > 0 else 'n√©gative'} avec {var}"
                
                return f"{emoji} **{var}**: {base_desc}"
            
            # Main analysis section
            st.markdown("## üìä Comprendre les Relations avec la Temp√©rature Ambiante")
            st.markdown("""
            Cette analyse identifie les facteurs qui influencent la temp√©rature ambiante dans votre centre de donn√©es.
            Les relations sont class√©es par ordre d'importance pour faciliter la prise de d√©cision.
            """)
            
            # Sort correlations by absolute value
            sorted_correlations = temp_correlations.abs().sort_values(ascending=False)
            
            # Key drivers section
            st.markdown("### üéØ Facteurs Principaux Affectant la Temp√©rature")
            
            # Identify top drivers
            top_drivers = []
            for var in sorted_correlations.index:
                corr_val = temp_correlations[var]
                if abs(corr_val) >= 0.3:  # Only significant correlations
                    top_drivers.append((var, corr_val))
            
            if top_drivers:
                st.markdown("**Facteurs ayant un impact significatif (class√©s par importance):**")
                
                for i, (var, corr_val) in enumerate(top_drivers, 1):
                    strength, emoji = interpret_correlation(corr_val)
                    
                    # Create readable variable names
                    var_display = {
                        'Temp_Exterieure': 'Temp√©rature Ext√©rieure',
                        'Puissance_IT': 'Charge IT',
                        'Porte_Status': '√âtat de la Porte',
                        'CLIM_A_Status': 'Climatisation A',
                        'CLIM_B_Status': 'Climatisation B',
                        'CLIM_C_Status': 'Climatisation C',
                        'CLIM_D_Status': 'Climatisation D'
                    }.get(var, var)
                    
                    impact_desc = get_relationship_description(var, corr_val)
                    st.markdown(f"{i}. {impact_desc}")
            else:
                st.info("Aucun facteur n'a d'impact significatif sur la temp√©rature pendant cette p√©riode.")
        
            # Detailed insights section
            st.markdown("### üí° Insights D√©taill√©s et Recommandations")
            
            # Create three columns for different categories
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("#### üå°Ô∏è Facteurs Environnementaux")
                if 'Temp_Exterieure' in temp_correlations:
                    ext_corr = temp_correlations['Temp_Exterieure']
                    if abs(ext_corr) > 0.5:
                        st.error(f"Impact √©lev√© de la temp√©rature ext√©rieure (corr√©lation: {ext_corr:.2f})")
                        st.markdown("**Recommandations:**")
                        st.markdown("- Am√©liorer l'isolation thermique")
                        st.markdown("- V√©rifier l'√©tanch√©it√© du b√¢timent")
                        st.markdown("- Installer des pare-soleil si n√©cessaire")
                    elif abs(ext_corr) > 0.3:
                        st.warning(f"Impact mod√©r√© de la temp√©rature ext√©rieure (corr√©lation: {ext_corr:.2f})")
                        st.markdown("**Recommandations:**")
                        st.markdown("- Surveiller lors des pics de chaleur")
                        st.markdown("- Planifier la maintenance pr√©ventive")
                    else:
                        st.success(f"Bonne isolation thermique (corr√©lation: {ext_corr:.2f})")
                        st.markdown("- L'isolation fonctionne bien")
                        st.markdown("- Maintenir les bonnes pratiques")
            
            with col2:
                st.markdown("#### ‚ùÑÔ∏è Syst√®me de Refroidissement")
                clim_effectiveness = []
                for col in clim_status_columns:
                    if col in temp_correlations:
                        clim_effectiveness.append((col, temp_correlations[col]))
                
                if clim_effectiveness:
                    effective_units = [unit for unit, corr in clim_effectiveness if corr < -0.2]
                    ineffective_units = [unit for unit, corr in clim_effectiveness if corr >= 0]
                    
                    if effective_units:
                        st.success(f"{len(effective_units)} unit√©(s) CLIM fonctionnent correctement")
                        for unit in effective_units:
                            unit_name = unit.replace('_Status', '')
                            st.markdown(f"- ‚úÖ {unit_name} r√©duit efficacement la temp√©rature")
                    
                    if ineffective_units:
                        st.error(f"{len(ineffective_units)} unit√©(s) CLIM n√©cessitent attention")
                        for unit in ineffective_units:
                            unit_name = unit.replace('_Status', '')
                            st.markdown(f"- ‚ö†Ô∏è {unit_name} pourrait n√©cessiter maintenance")
                        st.markdown("**Action requise:** V√©rifier l'efficacit√© de ces unit√©s")
                else:
                    st.info("Donn√©es CLIM non disponibles")
            
            with col3:
                st.markdown("#### üíª Charge IT et Acc√®s")
                if 'Puissance_IT' in temp_correlations:
                    it_corr = temp_correlations['Puissance_IT']
                    if abs(it_corr) > 0.5:
                        st.warning(f"Forte influence de la charge IT (corr√©lation: {it_corr:.2f})")
                        st.markdown("**Recommandations:**")
                        st.markdown("- Optimiser la distribution de charge")
                        st.markdown("- Consid√©rer l'ajout de capacit√© de refroidissement")
                    else:
                        st.success(f"Impact IT g√©rable (corr√©lation: {it_corr:.2f})")
                
                if 'Porte_Status' in temp_correlations:
                    door_corr = temp_correlations['Porte_Status']
                    if abs(door_corr) > 0.3:
                        st.warning(f"Impact des ouvertures de porte (corr√©lation: {door_corr:.2f})")
                        st.markdown("**Recommandations:**")
                        st.markdown("- Former le personnel aux bonnes pratiques")
                        st.markdown("- Installer des alertes pour portes ouvertes")
                    else:
                        st.success("Impact minimal des portes")
            
            # Summary and action plan
            st.markdown("### üìã Plan d'Action Prioritaire")
            
            # Generate priority actions based on correlations
            priority_actions = []
            
            # Check external temperature
            if 'Temp_Exterieure' in temp_correlations and abs(temp_correlations['Temp_Exterieure']) > 0.5:
                priority_actions.append(("Haute", "üî¥", "Am√©liorer l'isolation thermique du b√¢timent", 
                                        "La temp√©rature ext√©rieure a un impact trop important"))
            
            # Check CLIM effectiveness
            ineffective_clims = sum(1 for col in clim_status_columns 
                                   if col in temp_correlations and temp_correlations[col] >= 0)
            if ineffective_clims > 0:
                priority_actions.append(("Haute", "üî¥", f"Maintenance urgente de {ineffective_clims} unit√©(s) CLIM",
                                        "Certaines unit√©s ne refroidissent pas efficacement"))
            
            # Check IT load
            if 'Puissance_IT' in temp_correlations and temp_correlations['Puissance_IT'] > 0.6:
                priority_actions.append(("Moyenne", "üü°", "Optimiser la r√©partition de la charge IT",
                                        "La charge IT contribue significativement √† la chaleur"))
            
            # Check door impact
            if 'Porte_Status' in temp_correlations and abs(temp_correlations['Porte_Status']) > 0.4:
                priority_actions.append(("Moyenne", "üü°", "R√©viser les proc√©dures d'acc√®s",
                                        "Les ouvertures de porte affectent la temp√©rature"))
            
            if priority_actions:
                st.markdown("**Actions recommand√©es par ordre de priorit√©:**")
                
                # Sort by priority
                priority_order = {"Haute": 1, "Moyenne": 2, "Basse": 3}
                priority_actions.sort(key=lambda x: priority_order[x[0]])
                
                for priority, emoji, action, reason in priority_actions:
                    st.markdown(f"{emoji} **Priorit√© {priority}:** {action}")
                    st.markdown(f"   *Raison: {reason}*")
            else:
                st.success("‚úÖ Aucune action urgente requise. Le syst√®me fonctionne dans des param√®tres acceptables.")
            
            # Technical details expander for those who want more info
            with st.expander("üìä D√©tails Techniques (pour les experts)", expanded=False):
                st.markdown("#### Valeurs de Corr√©lation")
                
                # Create a clean dataframe for display
                tech_df = pd.DataFrame({
                    'Variable': temp_correlations.index,
                    'Corr√©lation': temp_correlations.values,
                    'Interpr√©tation': [interpret_correlation(x)[0] for x in temp_correlations.values],
                    'Impact': ['Positif' if x > 0 else 'N√©gatif' if x < 0 else 'Neutre' for x in temp_correlations.values]
                })
                tech_df = tech_df.sort_values('Corr√©lation', key=abs, ascending=False)
                
                st.dataframe(
                    tech_df.style.format({'Corr√©lation': '{:.3f}'})
                    .background_gradient(subset=['Corr√©lation'], cmap='RdBu_r', vmin=-1, vmax=1),
                    use_container_width=True
                )
                
                st.markdown("""
                **Guide d'interpr√©tation:**
                - **Corr√©lation positive:** Les deux variables √©voluent dans le m√™me sens
                - **Corr√©lation n√©gative:** Les variables √©voluent en sens oppos√©
                - **Valeur absolue:** Indique la force de la relation (0 = aucune, 1 = parfaite)
                - **M√©thode utilis√©e:** Corr√©lation de Spearman (robuste aux valeurs extr√™mes)
                """)
        
        else:
            if corr_matrix.empty:
                st.warning("‚ö†Ô∏è Impossible de calculer les relations entre variables. V√©rifiez la disponibilit√© des donn√©es.")
            else:
                st.warning("‚ö†Ô∏è La variable 'Temp_Ambiante' n'est pas disponible dans les donn√©es.")
    
    else:
        st.warning("‚ö†Ô∏è Pas assez de variables disponibles pour l'analyse des relations")

# 8. RAPPORTS
with tab8:
    st.header("üìã G√©n√©ration de rapports")
    st.info(f"üìÖ P√©riode s√©lectionn√©e: {start_date.strftime('%Y-%m-%d %H:%M')} - {end_date.strftime('%Y-%m-%d %H:%M')}")
    
    report_type = st.selectbox(
        "Type de rapport",
        ["Rapport quotidien", "Rapport hebdomadaire", "Rapport d'anomalies", "Rapport d'efficacit√© √©nerg√©tique"]
    )
    
    if report_type == "Rapport d'efficacit√© √©nerg√©tique":
        st.subheader("‚ö° Rapport d'efficacit√© √©nerg√©tique")
        
        # Explication du PUE
        with st.expander("üí° Comprendre le PUE (Power Usage Effectiveness)", expanded=True):
            st.write("""
            **Le PUE en termes simples :** Imaginez que votre data center est comme une voiture. Le PUE mesure combien d'√©nergie totale vous consommez pour faire fonctionner vos serveurs informatiques.
            
            üî¢ **Comment √ßa marche ?**
            - PUE = √ânergie totale du data center √∑ √ânergie des √©quipements IT
            - Un PUE de 2.0 signifie que pour chaque kWh utilis√© par vos serveurs, vous d√©pensez 1 kWh suppl√©mentaire en climatisation, √©clairage, etc.
            
            üéØ **Pourquoi viser 1.5 ?**
            - **PUE = 1.0** : Perfection th√©orique (impossible en pratique - il faut toujours de la climatisation!)
            - **PUE = 1.5** : Excellence industrielle - seulement 50% d'√©nergie en plus pour le refroidissement
            - **PUE = 2.0** : Acceptable mais perfectible - vous doublez votre consommation
            - **PUE > 2.5** : Inefficace - il est temps d'optimiser!
            
            üí∞ **Impact concret :** Si votre PUE passe de 2.0 √† 1.5, vous √©conomisez 25% sur votre facture d'√©lectricit√© totale!
            """)
        
        if all(col in filtered_merged_data.columns for col in ['Puissance_IT', 'Puissance_CLIM', 'Puissance_Generale']):
            # Calculs d'efficacit√©
            pue = filtered_merged_data['Puissance_Generale'] / filtered_merged_data['Puissance_IT']
            cooling_efficiency = filtered_merged_data['Puissance_CLIM'] / filtered_merged_data['Puissance_IT']
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("PUE Moyen", f"{pue.mean():.2f}")
            with col2:
                st.metric("Efficacit√© CLIM", f"{cooling_efficiency.mean():.2f}")
            with col3:
                energy_waste = (filtered_merged_data['Puissance_Generale'] - filtered_merged_data['Puissance_IT']).sum()
                st.metric("√ânergie non-IT totale", f"{energy_waste:.0f} kWh")
            
            # Graphique d'√©volution du PUE
            daily_pue = filtered_merged_data.copy()
            daily_pue['Date'] = daily_pue['Timestamp'].dt.date
            daily_pue['PUE'] = daily_pue['Puissance_Generale'] / daily_pue['Puissance_IT']
            daily_avg_pue = daily_pue.groupby('Date')['PUE'].mean().reset_index()
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=daily_avg_pue['Date'],
                y=daily_avg_pue['PUE'],
                mode='lines+markers',
                name='PUE journalier',
                line=dict(color='green', width=2)
            ))
            
            # Ligne de r√©f√©rence pour PUE id√©al
            fig.add_hline(y=1.5, line_dash="dash", line_color="red",
                         annotation_text="PUE cible: 1.5")
            
            fig.update_layout(
                title="√âvolution du PUE (Power Usage Effectiveness)",
                xaxis_title="Date",
                yaxis_title="PUE",
                height=500
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Recommandations
            st.subheader("üí° Recommandations d'optimisation")
            
            avg_pue = pue.mean()
            if avg_pue > 2.0:
                st.error(f"""
                ‚ö†Ô∏è **PUE √©lev√© d√©tect√© : {avg_pue:.2f}**
                
                Votre data center consomme plus du double de l'√©nergie n√©cessaire! 
                Pour chaque euro d√©pens√© en serveurs, vous d√©pensez {avg_pue-1:.2f}‚Ç¨ en infrastructure.
                
                **Actions recommand√©es :**
                - V√©rifier l'efficacit√© du syst√®me de refroidissement
                - Optimiser la circulation d'air (hot aisle/cold aisle)
                - Identifier et √©liminer les points chauds
                """)
            elif avg_pue > 1.5:
                st.warning(f"""
                ‚ö° **PUE mod√©r√© : {avg_pue:.2f}**
                
                Votre efficacit√© est correcte mais des √©conomies sont possibles!
                Potentiel d'√©conomie : environ {((avg_pue-1.5)/avg_pue)*100:.0f}% sur votre facture totale.
                
                **Suggestions d'am√©lioration :**
                - Augmenter l√©g√®rement la temp√©rature de consigne
                - Utiliser le free cooling quand possible
                - Optimiser la charge des serveurs
                """)
            else:
                st.success(f"""
                ‚úÖ **PUE excellent : {avg_pue:.2f}**
                
                F√©licitations! Votre data center est dans le top 10% mondial en efficacit√©.
                Vous ne d√©pensez que {(avg_pue-1)*100:.0f}% d'√©nergie suppl√©mentaire pour le refroidissement.
                
                **Continuez ainsi en :**
                - Maintenant cette performance
                - Partageant vos bonnes pratiques
                - Surveillant r√©guli√®rement les indicateurs
                """)
            
            # Analyse des p√©riodes de surconsommation
            high_consumption = filtered_merged_data[pue > pue.quantile(0.9)].copy()
            if not high_consumption.empty:
                high_consumption['Hour'] = high_consumption['Timestamp'].dt.hour
                peak_hours = high_consumption['Hour'].value_counts().head(3)
                
                st.write("**Heures de pic de consommation:**")
                for hour, count in peak_hours.items():
                    st.write(f"‚Ä¢ {hour}h00 - {hour+1}h00")

# 9. SIMULATION DE CO√õTS
with tab9:
    st.header("üí∞ Simulation et Analyse des Co√ªts √ânerg√©tiques")
    st.info(f"üìÖ P√©riode s√©lectionn√©e: {start_date.strftime('%Y-%m-%d %H:%M')} - {end_date.strftime('%Y-%m-%d %H:%M')}")
    
    # Explication
    st.info("""
    üí° **Cette section vous permet de:**
    - Calculer vos co√ªts √©nerg√©tiques actuels
    - Simuler des √©conomies potentielles
    - Comparer diff√©rents sc√©narios d'optimisation
    - Analyser l'impact financier du PUE
    """)
    
    if all(col in filtered_merged_data.columns for col in ['Puissance_IT', 'Puissance_CLIM', 'Puissance_Generale']):
        # Input pour le tarif √©lectrique
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            electricity_rate = st.number_input(
                "üíµ Tarif √©lectrique ($/kWh)",
                min_value=0.01,
                max_value=1.0,
                value=0.12,
                step=0.01,
                help="Entrez votre tarif √©lectrique actuel"
            )
        
        with col2:
            currency = st.selectbox(
                "Devise",
                ["USD ($)", "EUR (‚Ç¨)", "MAD (DH)"],
                index=0
            )
            currency_symbol = currency.split()[1].strip("()")
        
        # Calculs de base
        st.subheader("üìä Analyse des Co√ªts Actuels")
        
        # Calcul des consommations
        time_range = (filtered_merged_data['Timestamp'].max() - filtered_merged_data['Timestamp'].min()).total_seconds() / 3600
        
        # Consommations moyennes
        avg_it_power = filtered_merged_data['Puissance_IT'].mean()
        avg_clim_power = filtered_merged_data['Puissance_CLIM'].mean()
        avg_total_power = filtered_merged_data['Puissance_Generale'].mean()
        avg_pue = avg_total_power / avg_it_power if avg_it_power > 0 else 0
        
        # Co√ªts horaires, journaliers, mensuels et annuels
        hourly_cost = avg_total_power * electricity_rate
        daily_cost = hourly_cost * 24
        monthly_cost = daily_cost * 30
        annual_cost = daily_cost * 365
        
        # Affichage des m√©triques de co√ªt
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric(
                "üí∏ Co√ªt Horaire",
                f"{currency_symbol}{hourly_cost:.2f}",
                help="Co√ªt moyen par heure de fonctionnement"
            )
        with col2:
            st.metric(
                "üìÖ Co√ªt Journalier",
                f"{currency_symbol}{daily_cost:.2f}",
                delta=f"{currency_symbol}{daily_cost - (avg_it_power * 24 * electricity_rate):.2f} non-IT"
            )
        with col3:
            st.metric(
                "üìÜ Co√ªt Mensuel",
                f"{currency_symbol}{monthly_cost:,.2f}",
                help="Estimation sur 30 jours"
            )
        with col4:
            st.metric(
                "üóìÔ∏è Co√ªt Annuel",
                f"{currency_symbol}{annual_cost:,.2f}",
                help="Projection sur 365 jours"
            )
        
        # R√©partition des co√ªts
        st.subheader("üìä R√©partition des Co√ªts par Composant")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Camembert de r√©partition
            it_cost = avg_it_power * electricity_rate
            clim_cost = avg_clim_power * electricity_rate
            other_cost = (avg_total_power - avg_it_power - avg_clim_power) * electricity_rate
            
            fig_pie = go.Figure(data=[go.Pie(
                labels=['IT', 'Climatisation', 'Autres (√©clairage, etc.)'],
                values=[it_cost, clim_cost, other_cost],
                hole=.3,
                marker_colors=['#1f77b4', '#ff7f0e', '#2ca02c']
            )])
            
            fig_pie.update_layout(
                title=f"R√©partition des co√ªts horaires ({currency_symbol}/h)",
                height=400
            )
            st.plotly_chart(fig_pie, use_container_width=True)
        
        with col2:
            # Tableau de d√©tail
            cost_breakdown = pd.DataFrame({
                'Composant': ['√âquipements IT', 'Climatisation', 'Infrastructure', 'Total'],
                'Puissance (kW)': [avg_it_power, avg_clim_power, 
                                 avg_total_power - avg_it_power - avg_clim_power, avg_total_power],
                f'Co√ªt/heure ({currency_symbol})': [it_cost, clim_cost, other_cost, hourly_cost],
                f'Co√ªt/mois ({currency_symbol})': [it_cost * 720, clim_cost * 720, other_cost * 720, monthly_cost],
                '% du Total': [it_cost/hourly_cost * 100, clim_cost/hourly_cost * 100, 
                             other_cost/hourly_cost * 100, 100]
            })
            
            st.dataframe(
                cost_breakdown.style.format({
                    'Puissance (kW)': '{:.2f}',
                    f'Co√ªt/heure ({currency_symbol})': '{:.2f}',
                    f'Co√ªt/mois ({currency_symbol})': '{:,.2f}',
                    '% du Total': '{:.1f}%'
                }),
                use_container_width=True
            )
        
        # Simulation d'optimisation
        st.subheader("üöÄ Simulation d'Optimisation")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Ensure max_value is at least greater than min_value
            max_pue = max(avg_pue, 2.5)
            default_pue = 1.5 if avg_pue > 1.5 else max(1.2, avg_pue * 0.9)
            
            target_pue = st.slider(
                "PUE cible pour simulation",
                min_value=1.1,
                max_value=max_pue,
                value=default_pue,
                step=0.01,
                format="%.2f",
                help="Simulez l'impact d'une am√©lioration du PUE"
            )
        
        with col2:
            temp_increase = st.slider(
                "Augmentation temp√©rature (¬∞C)",
                min_value=0,
                max_value=5,
                value=2,
                step=1,
                help="Impact d'une augmentation de la temp√©rature de consigne"
            )
        
        # Calcul des √©conomies potentielles
        new_total_power = avg_it_power * target_pue
        power_savings = avg_total_power - new_total_power
        
        # Estimation de l'impact de la temp√©rature (r√®gle empirique : 4% d'√©conomie par ¬∞C)
        temp_savings_percent = temp_increase * 0.04
        clim_savings = avg_clim_power * temp_savings_percent
        total_savings = power_savings + clim_savings
        
        # Affichage des √©conomies
        st.subheader("üí∞ √âconomies Potentielles")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            hourly_savings = total_savings * electricity_rate
            st.metric(
                "√âconomies/heure",
                f"{currency_symbol}{hourly_savings:.2f}",
                delta=f"-{(total_savings/avg_total_power)*100:.1f}%"
            )
        
        with col2:
            monthly_savings = hourly_savings * 720
            st.metric(
                "√âconomies/mois",
                f"{currency_symbol}{monthly_savings:,.2f}",
                help="Sur base de 720 heures"
            )
        
        with col3:
            annual_savings = hourly_savings * 8760
            st.metric(
                "√âconomies/an",
                f"{currency_symbol}{annual_savings:,.2f}",
                help="Sur base de 8760 heures"
            )
        
        # Graphique de comparaison
        fig_comparison = go.Figure()
        
        categories = ['Actuel', f'PUE {target_pue}', f'+{temp_increase}¬∞C', 'Optimis√©']
        it_costs = [avg_it_power * electricity_rate] * 4
        clim_costs = [avg_clim_power * electricity_rate,
                     avg_clim_power * electricity_rate,
                     avg_clim_power * (1 - temp_savings_percent) * electricity_rate,
                     (new_total_power - avg_it_power - clim_savings) * electricity_rate]
        other_costs = [(avg_total_power - avg_it_power - avg_clim_power) * electricity_rate,
                      (new_total_power - avg_it_power - avg_clim_power) * electricity_rate,
                      (avg_total_power - avg_it_power - avg_clim_power) * electricity_rate,
                      0]
        
        fig_comparison.add_trace(go.Bar(name='IT', x=categories, y=it_costs, marker_color='#1f77b4'))
        fig_comparison.add_trace(go.Bar(name='Climatisation', x=categories, y=clim_costs, marker_color='#ff7f0e'))
        fig_comparison.add_trace(go.Bar(name='Autres', x=categories, y=other_costs, marker_color='#2ca02c'))
        
        fig_comparison.update_layout(
            title=f"Comparaison des sc√©narios de co√ªts ({currency_symbol}/heure)",
            barmode='stack',
            yaxis_title=f"Co√ªt ({currency_symbol}/h)",
            height=400
        )
        
        st.plotly_chart(fig_comparison, use_container_width=True)
        
        # ROI et temps de retour
        st.subheader("üìà Retour sur Investissement")
        
        investment = st.number_input(
            f"üíº Investissement estim√© pour optimisation ({currency_symbol})",
            min_value=0,
            value=50000,
            step=1000,
            help="Co√ªt estim√© des am√©liorations (isolation, free cooling, etc.)"
        )
        
        if annual_savings > 0 and investment > 0:
            roi_years = investment / annual_savings
            roi_months = roi_years * 12
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "‚è±Ô∏è Temps de retour",
                    f"{roi_years:.1f} ans",
                    help="Dur√©e pour r√©cup√©rer l'investissement"
                )
            
            with col2:
                roi_percent = (annual_savings / investment) * 100
                st.metric(
                    "üìä ROI annuel",
                    f"{roi_percent:.1f}%",
                    help="Retour sur investissement par an"
                )
            
            with col3:
                five_year_profit = (annual_savings * 5) - investment
                st.metric(
                    "üíµ Profit sur 5 ans",
                    f"{currency_symbol}{five_year_profit:,.0f}",
                    help="√âconomies nettes apr√®s investissement"
                )
        
        # Recommandations personnalis√©es
        st.subheader("üéØ Recommandations Personnalis√©es")
        
        if avg_pue > 2.0:
            st.error("""
            **Actions prioritaires pour r√©duire les co√ªts:**
            1. üîß Audit √©nerg√©tique complet du syst√®me de refroidissement
            2. üå°Ô∏è Augmentation progressive de la temp√©rature de consigne
            3. üí® Mise en place du free cooling si possible
            4. üîå Consolidation des serveurs sous-utilis√©s
            """)
        elif avg_pue > 1.5:
            st.warning("""
            **Opportunit√©s d'√©conomies identifi√©es:**
            1. üìä Optimisation de la distribution d'air (containment)
            2. üå°Ô∏è Ajustement fin des param√®tres de climatisation
            3. üí° Passage √† l'√©clairage LED si pas d√©j√† fait
            4. üîÑ Mise √† jour des √©quipements les moins efficaces
            """)
        else:
            st.success("""
            **Maintenir l'excellence √©nerg√©tique:**
            1. ‚úÖ Surveillance continue des m√©triques
            2. üîÑ Maintenance pr√©ventive r√©guli√®re
            3. üìà Benchmarking avec les meilleures pratiques
            4. üå± Explorer les √©nergies renouvelables
            """)
        
    else:
        st.warning("Donn√©es de puissance manquantes pour l'analyse des co√ªts.")

# Footer
st.markdown("---")
st.caption("üè¢ BGU-ONE Data Center Monitoring Dashboard | ¬© 2025")